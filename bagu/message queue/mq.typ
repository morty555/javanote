= 面试篇
+ 什么是消息队列？
  - 你可以把消息队列理解为一个使用队列来通信的组件。它的本质，就是个转发器，包含发消息、存消息、消费消息的过程。最简单的消息队列模型如下：
  #image("Screenshot_20250828_204856.png")
  - 我们通常说的消息队列，简称MQ（Message Queue），它其实就指消息中间件，当前业界比较流行的开源消息中间件包括：RabbitMQ、RocketMQ、Kafka。
+ 消息队列怎么选型？
  #image("Screenshot_20250828_204931.png")
  - 选型的时候，我们需要根据业务场景，结合上述特性来进行选型。
  - 比如你要支持天猫双十一类超大型的秒杀活动，这种一锤子买卖，那管理界面、消息回溯啥的不重要。我们需要看什么？看吞吐量！所以优先选Kafka和RocketMQ这种更高吞吐的。
  - 比如做一个公司的中台，对外提供能力，那可能会有很多主题接入，这时候主题个数又是很重要的考量，像Kafka这样百级的，就不太符合要求，可以根据情况考虑千级的RocketMQ，甚至百万级的RabbitMQ。
  - 又比如是一个金融类业务，那么重点考虑的就是稳定性、安全性，分布式部署的Kafka和Rocket就更有优势。
  - 特别说一下时效性，RabbitMQ以微秒的时效作为招牌，但实际上毫秒和微秒，在绝大多数情况下，都没有感知的区别，加上网络带来的波动，这一点在生产过程中，反而不会作为重要的考量。
  - 其它的特性，如消息确认、消息回溯，也经常作为考量的场景，管理界面的话试公司而定了
  - 这里的中台简单指的是把可复用的能力沉淀下来，服务多个前台，提升整体敏捷性。
+ 消息队列使用场景有哪些？
  - 解耦：可以在多个系统之间进行解耦，将原本通过网络之间的调用的方式改为使用MQ进行消息的异步通讯，只要该操作不是需要同步的，就可以改为使用MQ进行不同系统之间的联系，这样项目之间不会存在耦合，系统之间不会产生太大的影响，就算一个系统挂了，也只是消息挤压在MQ里面没人进行消费而已，不会对其他的系统产生影响。
  - 异步：加入一个操作设计到好几个步骤，这些步骤之间不需要同步完成，比如客户去创建了一个订单，还要去客户轨迹系统添加一条轨迹、去库存系统更新库存、去客户系统修改客户的状态等等。这样如果这个系统都直接进行调用，那么将会产生大量的时间，这样对于客户是无法接受的；并且像添加客户轨迹这种操作是不需要去同步操作的，如果使用MQ将客户创建订单时，将后面的轨迹、库存、状态等信息的更新全都放到MQ里面然后去异步操作，这样就可加快系统的访问速度，提供更好的客户体验。
  - 削峰：一个系统访问流量有高峰时期，也有低峰时期，比如说，中午整点有一个抢购活动等等。比如系统平时流量并不高，一秒钟只有100多个并发请求，系统处理没有任何压力，一切风平浪静，到了某个抢购活动时间，系统并发访问了剧增，比如达到了每秒5000个并发请求，而我们的系统每秒只能处理2000个请求，那么由于流量太大，我们的系统、数据库可能就会崩溃。这时如果使用MQ进行流量削峰，将用户的大量消息直接放到MQ里面，然后我们的系统去按自己的最大消费能力去消费这些消息，就可以保证系统的稳定，只是可能要跟进业    务逻辑，给用户返回特定页面或者稍后通过其他方式通知其结果
+ 消息重复消费怎么解决？
  - 生产端为了保证消息发送成功，可能会重复推送(直到收到成功ACK)，会产生重复消息。但是一个成熟的MQ Server框架一般会想办法解决，避免存储重复消息(比如：空间换时间，存储已处理过的message_id)，给生产端提供一个幂等性的发送消息接口。
  - 但是消费端却无法根本解决这个问题，在高并发标准要求下，拉取消息+业务处理+提交消费位移需要做事务处理，另外消费端服务可能宕机，很可能会拉取到重复消息。
  - 所以，只能业务端自己做控制，对于已经消费成功的消息，本地数据库表或Redis缓存业务标识，每次处理前先进行校验，保证幂等。
+ 消息丢失怎么解决的？
  - 使用一个消息队列，其实就分为三大块：生产者、中间件、消费者，所以要保证消息就是保证三个环节都不能丢失数据。
  - 消息生产阶段：生产者会不会丢消息，取决于生产者对于异常情况的处理是否合理。从消息被生产出来，然后提交给 MQ 的过程中，只要能正常收到 （ MQ 中间件） 的 ack 确认响应，就表示发送成功，所以只要处理好返回值和异常，如果返回异常则进行消息重发，那么这个阶段是不会出现消息丢失的。
  - 消息存储阶段：Kafka 在使用时是部署一个集群，生产者在发布消息时，队列中间件通常会写「多个节点」，也就是有多个副本，这样一来，即便其中一个节点挂了，也能保证集群的数据不丢失。
  - 消息消费阶段：消费者接收消息+消息处理之后，才回复 ack 的话，那么消息阶段的消息不会丢失。不能收到消息就回 ack，否则可能消息处理中    途挂掉了，消息就丢失了。
+ 使用消息队列还应该注意哪些问题？
  - 需要考虑消息可靠性和顺序性方面的问题。
+ 消息队列的可靠性、顺序性怎么保证？
  - 消息可靠性可以通过下面这些方式来保证
    - 消息持久化：确保消息队列能够持久化消息是非常关键的。在系统崩溃、重启或者网络故障等情况下，未处理的消息不应丢失。例如，像 RabbitMQ 可以通过配置将消息持久化到磁盘，通过将队列和消息都设置为持久化的方式（设置durable = true），这样在服务器重启后，消息依然可以被重新读取和处理。
    - 消息确认机制：消费者在成功处理消息后，应该向消息队列发送确认（acknowledgment）。消息队列只有收到确认后，才会将消息从队列中移除。如果没有收到确认，消息队列可能会在一定时间后重新发送消息给其他消费者或者再次发送给同一个消费者。以 Kafka 为例，消费者通过commitSync或者commitAsync方法来提交偏移量（offset），从而确认消息的消费。
    - 消息重试策略：当消费者处理消息失败时，需要有合理的重试策略。可以设置重试次数和重试间隔时间。例如，在第一次处理失败后，等待一段时间（如 5 秒）后进行第二次重试，如果重试多次（如 3 次）后仍然失败，可以将消息发送到死信队列，以便后续人工排查或者采取其他特殊处理。
  - 消息顺序性保证的方式如下：
    - 有序消息处理场景识别：首先需要明确业务场景中哪些消息是需要保证顺序的。例如，在金融交易系统中，对于同用户的转账操作顺序是不能打乱的。对于需要顺序处理的消息，要确保消息队列和消费者能够按照特定的顺序进行处理。
    - 消息队列对顺序性的支持：部分消息队列本身提供了顺序性保证的功能。比如 Kafka 可以通过将消息划分到同一个分区（Partition）来保证消息在分区内是有序的，消费者按照分区顺序读取消息就可以保证消息顺序。但这也可能会限制消息的并行处理程度，需要在顺序性和吞吐量之间进行权衡
    - 消费者顺序处理策略：消费者在处理顺序消息时，应该避免并发处理可能导致顺序打乱的情况。例如，可以通过单线程或者使用线程池并对顺序消息进    行串行化处理等方式，确保消息按照正确的顺序被消费。
+ 如何保证幂等写？
  - 幂等性是指 同一操作的多次执行对系统状态的影响与一次执行结果一致。例如，支付接口若因网络重试被多次调用，最终应确保仅扣款一次。实现幂等写的核心方案：
    - 唯一标识（幂等键）：客户端为每个请求生成全局唯一ID（如 UUID、业务主键），服务端校验该ID是否已处理，适用场景接口调用、消息消费等。
    - 数据库事务 + 乐观锁：通过版本号或状态字段控制并发更新，确保多次更新等同于单次操作，适用场景数据库记录更新（如余额扣减、订单状态变更）。
    - 数据库唯一约束：利用数据库唯一索引防止重复数据写入，适用场景数据插入场景（如订单创建）。
    - 分布式锁：通过锁机制保证同一时刻仅有一个请求执行关键操作，适用场景高并发下的资源抢夺（如秒杀）。
    - 消息去重：消息队列生产者为每条消息生成唯一的消息 ID，    消费者在处理消息前，先检查该消息 ID 是否已经处理过，如果已经处理过则丢弃该消息。
+ 如何处理消息队列的消息积压问题？
  - 消息积压是因为生产者的生产速度，大于消费者的消费速度。遇到消息积压问题时，我们需要先排查，是不是有bug产生了。
  - 如果不是bug，我们可以优化一下消费的逻辑，比如之前是一条一条消息消费处理的话，我们可以确认是不是可以优为批量处理消息。如果还是慢，我们可以考虑水平扩容，增加Topic的队列数，和消费组机器的数量，提升整体消费能力。
  - 如果是bug导致几百万消息持续积压几小时。有如何处理呢？需要解决bug，临时紧急扩容，大概思路如下：
  #image("Screenshot_20250828_214619.png")
  - 其实就是修好bug后，新建一个数倍的消费程序消费掉堆积的信息，消费完之后又恢复原先架构
+ 如何保证数据一致性，事务消息如何实现？
  - 一条普通的MQ消息，从产生到被消费，大概流程如下：
  #image("Screenshot_20250829_110405-1.png")
    + 生产者产生消息，发送带MQ服务器
    + MQ收到消息后，将消息持久化到存储系统。
    + MQ服务器返回ACk到生产者。
    + MQ服务器把消息push给消费者
    + 消费者消费完消息，响应ACK
    + MQ服务器收到ACK，认为消息消费成功，即在存储中删除消息。
  - 我们举个下订单的例子吧。订单系统创建完订单后，再发送消息给下游系统。如果订单创建成功，然后消息没有成功发送出去，下游系统就无法感知这个事情，出导致数据不一致。
  - 如何保证数据一致性呢？可以使用事务消息。一起来看下事务消息是如何实现的吧。
  #image("Screenshot_20250829_110507.png")
    + 生产者产生消息，发送一条半事务消息到MQ服务器
    + MQ收到消息后，将消息持久化到存储系统，这条消息的状态是待发送状态。
    + MQ服务器返回ACK确认到生产者，此时MQ不会触发消息推送事件
    + 生产者执行本地事务
    + 如果本地事务执行成功，即commit执行结果到MQ服务器；如果执行失败，发送rollback。
    + 如果是正常的commit，MQ服务器更新消息状态为可发送；如果是rollback，即删除消息。
    + 如果消息状态更新为可发送，则MQ服务器会push消息给消费者。消费者消费完就回ACK。
    + 如果MQ服务器长时间没有收到生产者的commit或者rollback，    它会反查生产者，然后根据查询到的结果执行最终状态。
    #image("Screenshot_20250829_111119.png")
  - 消息队列是参考哪种设计模式？
    - 是参考了观察者模式和发布订阅模式，两种设计模式思路是一样的
      - 观察者模式：某公司给自己员工发月饼发粽子，是由公司的行政部门发送的，这件事不适合交给第三方，原因是“公司”和“员工”是一个整体
        - 观察者模式实际上就是一个一对多的关系，在观察者模式中存在一个主题和多个观察者，主题也是被观察者，当我们主题发布消息时，会通知各个观察者，观察者将会收到最新消息，图解如下：每个观察者首先订阅主题，订阅成功后当主题发送消息时会循环整个观察者列表，逐一发送消息通知。 
        #image("Screenshot_20250829_111336.png")
      - 发布-订阅模式：某公司要给其他人发各种快递，因为“公司”和“其他人”是独立的，其唯一的桥梁是“快递”，所以这件事适合交给第三方快递公司解决
        - 发布订阅模式和观察者模式的区别就是发布者和订阅者完全解耦，通过中间的发布订阅中心进行消息通知，发布者并不知道自己发布的消息会通知给谁，因此发布订阅模式有三个重要角色，发布者->发布订阅中心->订阅者。
        - 图解如下：当发布者发布消息到发布订阅中心后，发布订阅中心会将消息通知给所有订阅该发布者的订阅者 
        #image("Screenshot_20250829_111415.png")
        #image("Screenshot_20250829_111553.png")
  - 让你写一个消息队列，该如何进行架构设计？
    - 这个问题面试官主要考察三个方面的知识点：
      - 你有没有对消息队列的架构原理比较了解
      - 考察你的个人设计能力
      - 考察编程思想，如什么高可用、可扩展性、幂等等等。
    - 遇到这种设计题，大部分人会很蒙圈，因为平时没有思考过类似的问题。大多数人平时埋头增删改啥，不去思考框架背后的一些原理。有很多类似的问题，比如让你来设计一个 Dubbo 框架，或者让你来设计一个MyBatis 框架，你会怎么思考呢？
    - 回答这类问题，并不要求你研究过那技术的源码，你知道那个技术框架的基本结构、工作原理即可。设计一个消息队列，我们可以从这几个角度去思考：
      + 首先是消息队列的整体流程，producer发送消息给broker，broker存储好，broker再发送给consumer消费，consumer回复消费确认等。
      + producer发送消息给broker，broker发消息给consumer消费，那就需要两次RPC了，RPC如何设计呢？可以参考开源框架Dubbo，你可以说说服务发现、序列化协议等等
      + broker考虑如何持久化呢，是放文件系统还是数据库呢，会不会消息堆积呢，消息堆积如何处理呢。
      + 消费关系如何保存呢？点对点还是广播方式呢？广播关系又是如何维护呢？zk还是config server
      + 消息可靠性如何保证呢？如果消息重复了，如何幂等处理呢？
      + 消息队列的高可用如何设计呢？可以参考Kafka的高可用保障机制。多副本 -> leader & follower -> broker 挂了重新选举 leader 即可对外服务。
      + 消息事务特性，与本地业务同个事务，本地消息落库;消息投递到服务端，本地才删除；定时任务扫描本地消息库，补偿发送。
      + MQ得伸缩性和可扩展性，如果消息积压或者资源不够时，如何支持快速扩容，提高吞吐？可以参照一下 Kafka 的设计理念，broker -> topic -> partition，每个 partition 放一个机器，就存一部分数据。如果现在资源不够了，简单啊，给 topic 增加 partition，    然后做数据迁移，增加机器，不就可以存放更多数据，提供更高的吞吐量了。
+ RocketMQ
  -  消息队列为什么选择RocketMQ的？
    - 开发语言优势。RocketMQ 使用 Java 语言开发，比起使用 Erlang 开发的 RabbitMQ 来说，有着更容易上手的阅读体验和受众。大部分熟悉 Java 的同学都可以深入阅读其源码，分析、排查问题。
    - 社区氛围活跃。RocketMQ 是阿里巴巴开源且内部在大量使用的消息队列
    - 特性丰富。根据 RocketMQ 官方文档的列举，其高级特性达到了 12 种，例如顺序消息、事务消息、消息过滤、定时消息等。顺序消息、事务消息、消息过滤、定时消息。
  - RocketMQ和Kafka的区别是什么？如何做技术选型？
    - Kafka的优缺点：
      - 优点：
        - 高吞吐量。在普通机器4CPU8G的配置下，一台机器可以抗住十几万的QPS
        - 集群部署。如果部分机器宕机不可用，则不影响Kafka的正常使用。
      - 缺点
        - 数据丢失。因为它在收到消息的时候，并不是直接写到物理磁盘的，而是先写入到磁盘缓冲区里面的。
        - Kafka功能比较的单一 主要的就是支持收发消息，高级功能基本没有，就会造成适用场景受限。
    - RocketMQ
      - 优点： 
        - 支持功能比较多，比如延迟队列、消息事务等等
        - 吞吐量高。单机吞吐量达到 10 万级
        - 支持大规模集群部署，线性扩展方便
        - Java语言开发，满足了国内绝大部分公司技术栈
      - 缺点：
        - 性能相比 kafka 是弱一点，因为 kafka 用到了 sendfile 的零拷贝技术
        - 而 RocketMQ 主要是用 mmap+write 来实现零拷贝。
    - 如何选择：
      - 如果我们业务只是收发消息这种单一类型的需求，而且可以允许小部分数据丢失的可能性，但是又要求极高的吞吐量和高性能的话，就直接选Kafka就行了，就好比我们公司想要收集和传输用户行为日志以及其他相关日志的处理，就选用的Kafka中间件。
      - 如果公司的需要通过 mq 来实现一些业务需求，比如延迟队列、消息事务等，    公司技术栈主要是Java语言的话，就直接一步到位选择RocketMQ，这样会省很多事情。
    -  RocketMQ延时消息的底层原理
      - broker 在接收到延时消息的时候，会将延时消息存入到延时Topic的队列中。然后ScheduleMessageService中，每个 queue 对应的定时任务会不停地被执行，检查 queue 中哪些消息已到设定时间，然后转发到消息的原始Topic，这些消息就会被各自的 producer 消费了。
    - RocektMQ怎么处理分布式事务？
      - RocketMQ是一种最终一致性的分布式事务，就是说它保证的是消息最终一致性，而不是像2PC、3PC、TCC那样强一致分布式事务
      - 分布式事务：为了解决微服务架构（形式都是分布式系统）中不同节点之间的数据一致性问题。即一个请求在多个微服务调用链中，所有服务的数据处理要么全部成功，要么全部回滚。
      举例：#image("Screenshot_20250901_111933.png")
      - 2pc，3pc,tcc不了解
        - 
      


+ RabbitMQ
  - RabbitMQ的特性你知道哪些？
    - RabbitMQ 以 可靠性、灵活性 和 易扩展性 为核心优势，适合需要稳定消息传递的复杂系统。其丰富的插件和协议支持使其在微服务、IoT、金融等领域广泛应用，比较核心的特性有如下：
      - 持久化机制：RabbitMQ 支持消息、队列和交换器的持久化。当启用持久化时，消息会被写入磁盘，即使 RabbitMQ 服务器重启，消息也不会丢失。例如，在声明队列时可以设置 durable 参数为 true 来实现队列的持久化：
      - 消息确认机制：提供了生产者确认和消费者确认机制。生产者可以设置 confirm 模式，当消息成功到达 RabbitMQ 服务器时，会收到确认消息；消费者在处理完消息后，可以向 RabbitMQ 发送确认信号，告知服务器该消息已被成功处理，服务器才会将消息从队列中删除。
      - 镜像队列：支持创建镜像队列，将队列的内容复制到多个节点上，提高消息的可用性和可靠性。当一个节点出现故障时，其他节点仍然可以提供服务，确保消息不会丢失。
      - 多种交换器类型：RabbitMQ 提供了多种类型的交换器，如直连交换器（Direct Exchange）、扇形交换器（Fanout Exchange）、主题交换器（Topic Exchange）和头部交换器（Headers Exchange）。不同类型的交换器根据不同的规则将消息路由到队列中。例如，扇形交换器会将接收到的消息广播到所有绑定的队列中；主题交换器则根据消息的路由键和绑定键的匹配规则进行路由。

  - RabbitMQ的底层架构是什么？
    - 核心组件：生产者负责发送消息到 RabbitMQ、消费者负责从 RabbitMQ 接收并处理消息、RabbitMQ 本身负责存储和转发消息。
    - 交换机：交换机接收来自生产者的消息，并根据 routing key 和绑定规则将消息路由到一个或多个队列。
    - 持久化：RabbitMQ 支持消息的持久化，可以将消息保存在磁盘上，以确保在 RabbitMQ 重启后消息不丢失，队列也可以设置为持久化，以保证其结构在重启后不会丢失。
    - 确认机制：为了确保消息可靠送达，RabbitMQ 使用确认机制，消费费者在处理完消息后发送确认给 RabbitMQ，未确认的消息会重新入队。
    - 高可用性：RabbitMQ 提供了集群模式，可以将多个 RabbitMQ 实例组成一个集群，以提高可用性和负载均衡。通过镜像队列，可以在多个节点上复制同一队列的内容，以防止单点故障。

  - 消息队列一但创建不能修改，如果需要绑定新的交换机或者增加其他属性，需要删掉原有队列再次生成
  - CorrelationData 就像消息的 身份牌，用来在 RabbitMQ 发送确认回调中追踪消息，方便做重试、落库或幂等处理。 
    ```java
    CorrelationData correlationData = new CorrelationData(taskId);
    rabbitTemplate.convertAndSend(exchange, routingKey, message, correlationData);
 
    ```
  - setConfirmCallback在生产端设置ack确认