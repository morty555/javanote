+ 基础篇
  - 执行一条 select 语句，期间发生了什么？
    - MySQL 执行流程是怎样的？
      #image("Screenshot_20250821_102318.png")
      -  MySQL 的架构共分为两层：Server 层和存储引擎层
      - Server 层负责建立连接、分析和执行 SQL。MySQL 大多数的核心功能模块都在这实现，主要包括连接器，查询缓存、解析器、预处理器、优化器、执行器等。另外，所有的内置函数（如日期、时间、数学和加密函数等）和所有跨存储引擎的功能（如存储过程、触发器、视图等。）都在 Server 层实现。
      - 存储引擎层负责数据的存储和提取。支持InnoDB、MyISAM、Memory 等多个存储引擎，不同的存储引擎共用一个 Server 层。现在最常用的存储引擎是 InnoDB，从 MySQL 5.5 版本开始， InnoDB 成为了 MySQL 的默认存储引擎。我们常说的索引数据结构，就是由存储引擎层实现的，不同的存储引擎支持的索引类型也不相同，比如 InnoDB 支持索引类型是 B+树 ，且是默认使用，也就是说在数据表中创建的主键索引和二级索引默认使用的是 B+ 树索引。
    -  第一步：连接器
       - 如果你在 Linux 操作系统里要使用 MySQL，那你第一步肯定是要先连接 MySQL 服务，然后才能执行 SQL 语句
       - 连接的过程需要先经过 TCP 三次握手，因为 MySQL 是基于 TCP 协议进行传输的，如果 MySQL 服务并没有启动，则会收到如下的报错
       #image("image.png")
       - 如果 MySQL 服务正常运行，完成 TCP 连接的建立后，连接器就要开始验证你的用户名和密码，如果用户名或密码不对，就收到一个"Access denied for user"的错误，然后客户端程序结束执行。
       - 如果用户密码都没有问题，连接器就会获取该用户的权限，然后保存起来，后续该用户在此连接里的任何操作，都会基于连接开始时读到的权限进行权限逻辑的判断
       - 所以，如果一个用户已经建立了连接，即使管理员中途修改了该用户的权限，也不会影响已经存在连接的权限。修改完成后，只有再新建的连接才会使用新的权限设置。
       - 如何查看 MySQL 服务被多少个客户端连接了？
         - show processlist 命令
       - 空闲连接会一直占用着吗？
         - MySQL 定义了空闲连接的最大空闲时长，由 wait_timeout 参数控制的，默认值是 8 小时
       - 我们自己也可以手动断开空闲的连接，使用的是 kill connection + id 的命令。
       - 一个处于空闲状态的连接被服务端主动断开后，这个客户端并不会马上知道，等到客户端在发起下一个请求的时候，才会收到这样的报错等到客户端在发起下一个请求的时候，才会收到这样的报错 Lost connection to MySQL server during query
       - MySQL 的连接数有限制吗？
         - MySQL 服务支持的最大连接数由 max_connections 参数控制
       - MySQL 的连接也跟 HTTP 一样，有短连接和长连接的概念，它们的区别如下：
       #image("Screenshot_20250821_103442.png")
       - 怎么解决长连接占用内存的问题？
         + 定期断开长连接。既然断开连接后就会释放连接占用的内存资源，那么我们可以定期断开长连接。
         + 客户端主动重置连接。MySQL 5.7 版本实现了 mysql_reset_connection() 函数的接口，注意这是接口函数不是命令，那么当客户端执行了一个很大的操作后，在代码里调用 mysql_reset_connection 函数来重置连接，达到释放内存的效果。这个过程不需要重连和重新做权限验证，但是会将连接恢复到刚刚创建完时的状态。
       - 至此，连接器的工作做完了，简单总结一下：
         - 与客户端进行 TCP 三次握手建立连接；
         - 校验客户端的用户名和密码，如果用户名或密码不对，则会报错；
         - 如果用户名和密码都对了，会读取该用户的权限，然后后面的权限逻辑判断都基于此时读取到的权限；
    - 第二步：查询缓存
      - 连接器得工作完成后，客户端就可以向 MySQL 服务发送 SQL 语句了，MySQL 服务收到 SQL 语句后，就会解析出 SQL 语句的第一个字段，看看是什么类型的语句
      - 如果 SQL 是查询语句（select 语句），MySQL 就会先去查询缓存（ Query Cache ）里查找缓存数据，看看之前有没有执行过这一条命令，这个查询缓存是以 key-value 形式保存在内存中的，key 为 SQL 查询语句，value 为 SQL 语句查询的结果。
      - 如果查询的语句命中查询缓存，那么就会直接返回 value 给客户端。如果查询的语句没有命中查询缓存中，那么就要往下继续执行，等执行完后，查询的结果就会被存入查询缓存中。
      - 这么看，查询缓存还挺有用，但是其实查询缓存挺鸡肋的。
      - 对于更新比较频繁的表，查询缓存的命中率很低的，因为只要一个表有更新操作，那么这个表的查询缓存就会被清空。如果刚缓存了一个查询结果很大的数据，还没被使用的时候，刚好这个表有更新操作，查询缓冲就被清空了，相当于缓存了个寂寞。
      - 所以，MySQL 8.0 版本直接将查询缓存删掉了，也就是说 MySQL 8.0 开始，执行一条 SQL 查询语句，不会再走到查询缓存这个阶段了。
      - 对于 MySQL 8.0 之前的版本，如果想关闭查询缓存，我们可以通过将参数 query_cache_type 设置成 DEMAND。
      - 这里说的查询缓存是 server 层的，也就是 MySQL 8.0 版本移除的是 server 层的查询缓存，并不是 Innodb 存储引擎中的 buffer pool。
    - 第三步：解析 SQL
      - 解析器会做如下两件事情。
        + 第一件事情，词法分析。MySQL 会根据你输入的字符串识别出关键字出来，例如，SQL语句 select username from userinfo，在分析之后，会得到4个Token，其中有2个Keyword，分别为select和from：
        + 第二件事情，语法分析。根据词法分析的结果，语法解析器会根据语法规则，判断你输入的这个 SQL 语句是否满足 MySQL 语法，如果没问题就会构建出 SQL 语法树，这样方便后面模块获取 SQL 类型、表名、字段名、 where 条件等等。
        - 如果我们输入的 SQL 语句语法不对，就会在解析器这个阶段报错。
        - 但是注意，表不存在或者字段不存在，并不是在解析器里做的，《MySQL 45 讲》说是在解析器做的，但是经过我和朋友看 MySQL 源码（5.7和8.0）得出结论是解析器只负责检查语法和构建语法树，但是不会去查表或者字段存不存在。
    - 第四步：执行 SQL
      - 经过解析器后，接着就要进入执行 SQL 查询语句的流程了，每条SELECT 查询语句流程主要可以分为下面这三个阶段：
        - prepare 阶段，也就是预处理阶段；
        - optimize 阶段，也就是优化阶段；
        - execute 阶段，也就是执行阶段；
      - 预处理器
        - 我们先来说说预处理阶段做了什么事情。
          - 检查 SQL 查询语句中的表或者字段是否存在；
          - 将 select \* 中的 \* 符号，扩展为表上的所有列；
          -  不过，对于 MySQL 5.7 判断表或字段是否存在的工作，是在词法分析&语法分析之后，prepare 阶段之前做的。结论都一样，不是在解析器里做的。正因为 MySQL 5.7 代码结构不好，所以 MySQL 8.0 代码结构变化很大，后来判断表或字段是否存在的工作就被放入到 prepare 阶段做了。
      - 优化器
        - 经过预处理阶段后，还需要为 SQL 查询语句先制定一个执行计划，这个工作交由「优化器」来完成的。
        - 优化器主要负责将 SQL 查询语句的执行方案确定下来，比如在表里面有多个索引的时候，优化器会基于查询成本的考虑，来决定选择使用哪个索引。
        - 要想知道优化器选择了哪个索引，我们可以在查询语句最前面加个 explain 命令，这样就会输出这条 SQL 语句的执行计划，然后执行计划中的 key 就表示执行过程中使用了哪个索引,比如下图的 key 为 PRIMARY 就是使用了主键索引。,如果查询语句的执行计划里的 key 为 null 说明没有使用索引，那就会全表扫描（type = ALL）
        - 覆盖索引:当一个查询所需要的字段，全部都能从索引里获取到，而不需要回表（访问实际的数据行），这个索引就是“覆盖索引”。

        select id from product where id > 1 and name like 'i%';
        - 这条查询语句的结果既可以使用主键索引，也可以使用普通索引，但是执行的效率会不同。
        - 很显然这条查询语句是覆盖索引，直接在二级索引就能查找到结果（因为二级索引的 B+ 树的叶子节点的数据存储的是主键值），就没必要在主键索引查找了，因为查询主键索引的 B+ 树的成本会比查询二级索引的 B+ 的成本大,优化器基于查询成本的考虑，会选择查询代价小的普通索引。
        #image("Screenshot_20250821_105538.png")
        #image("Screenshot_20250821_105548.png")
      -  执行器
        - 经历完优化器后，就确定了执行方案，接下来 MySQL 就真正开始执行语句了，这个工作是由「执行器」完成的。执行器就会和存储引擎交互了，交互是以记录为单位的。
        - 接下来，用三种方式执行过程，跟大家说一下执行器和存储引擎的交互过程(PS ：为了写好这一部分，特地去看 MySQL 源码，也是第一次看哈哈）。
        - 主键索引查询
          - 以本文开头查询语句为例，看看执行器是怎么工作的。select \* from product where id = 1;
            - 这条查询语句的查询条件用到了主键索引，而且是等值查询，同时主键 id 是唯一，不会有 id 相同的记录，所以优化器决定选用访问类型为 const 进行查询，也就是使用主键索引查询一条记录，那么执行器与存储引擎的执行流程是这样的：
              - 执行器第一次查询，会调用 read_first_record 函数指针指向的函数，因为优化器选择的访问类型为 const，这个函数指针被指向为 InnoDB 引擎索引查询的接口，把条件 id = 1 交给存储引擎，让存储引擎定位符合条件的第一条记录。
                - const 类型表示：查询条件能唯一定位一条记录（比如 PRIMARY KEY 或者 UNIQUE 索引）。所以执行器只需要调用一次 read_first_record() 就够了，因为最多只会返回一条。
              - 存储引擎通过主键索引的 B+ 树结构定位到 id = 1的第一条记录，如果记录是不存在的，就会向执行器上报记录找不到的错误，然后查询结束。如果记录是存在的，就会将记录返回给执行器；
              - 执行器从存储引擎读到记录后，接着判断记录是否符合查询条件，如果符合则发送给客户端，如果不符合则跳过该记录。
              #image("Screenshot_20250821_110658.png")
                - InnoDB 将行数据（row buffer）传给执行器。
                - 执行器判断需要的列（name, age），丢掉不需要的列，返回给客户端。
              - 执行器查询的过程是一个 while 循环，所以还会再查一次，但是这次因为不是第一次查询了，所以会调用 read_record 函数指针指向的函数，因为优化器选择的访问类型为 const，这个函数指针被指向为一个永远返回 - 1 的函数，所以当调用该函数的时候，执行器就退出循环，也就是结束查询
        - 全表扫描
          - select \* from product where name = 'iphone';
          - 这条查询语句的查询条件没有用到索引，所以优化器决定选用访问类型为 ALL 进行查询，也就是全表扫描的方式查询，那么这时执行器与存储引擎的执行流程是这样的：
            - 执行器第一次查询，会调用 read_first_record 函数指针指向的函数，因为优化器选择的访问类型为 all，这个函数指针被指向为 InnoDB 引擎全扫描的接口，让存储引擎读取表中的第一条记录；
            - 执行器会判断读到的这条记录的 name 是不是 iphone，如果不是则跳过；如果是则将记录发给客户端(是的没错，Server 层每从存储引擎读到一条记录就会发送给客户端，之所以客户端显示的时候是直接显示所有记录的，是因为客户端是等查询语句查询完成后，才会显示出所有的记录）。
            - 执行器查询的过程是一个 while 循环，所以还会再查一次，会调用 read_record 函数指针指向的函数，因为优化器选择的访问类型为 all，read_record 函数指针指向的还是 InnoDB 引擎全扫描的接口，所以接着向存储引擎层要求继续读刚才那条记录的下一条记录，存储引擎把下一条记录取出后就将其返回给执行器（Server层），执行器继续判断条件，不符合查询条件即跳过该记录，否则发送到客户端；
            - 一直重复上述过程，直到存储引擎把表中的所有记录读完，然后向执行器（Server层） 返回了读取完毕的信息；
            - 执行器收到存储引擎报告的查询完毕的信息，退出循环，停止查询。
        - 索引下推
          - MySQL 5.6 推出的查询优化策略
          - 索引下推能够减少二级索引在查询时的回表操作，提高查询的效率，因为它将 Server 层部分负责的事情，交给存储引擎层去处理了。
          - 举一个具体的例子，方便大家理解，这里一张用户表如下，我对 age 和 reward 字段建立了联合索引
          - 现在有下面这条查询语句：elect \* from t_user  where age > 20 and reward = 100000;
          - 联合索引当遇到范围查询 (>、<) 就会停止匹配，也就是 age 字段能用到联合索引，但是 reward 字段则无法利用到索引。
          - 那么，不使用索引下推（MySQL 5.6 之前的版本）时，执行器与存储引擎的执行流程是这样的：
            - Server 层首先调用存储引擎的接口定位到满足查询条件的第一条二级索引记录，也就是定位到 age > 20 的第一条记录；
            - 存储引擎根据二级索引的 B+ 树快速定位到这条记录后，获取主键值，然后进行回表操作，将完整的记录返回给 Server 层；
            - Server 层在判断该记录的 reward 是否等于 100000，如果成立则将其发送给客户端；否则跳过该记录；
            - 接着，继续向存储引擎索要下一条记录，存储引擎在二级索引定位到记录后，获取主键值，然后回表操作，将完整的记录返回给 Server 层；
            - 如此往复，直到存储引擎把表中的所有记录读完。
            - 可以看到，没有索引下推的时候，每查询到一条二级索引记录，都要进行回表操作，然后将记录返回给 Server，接着 Server 再判断该记录的 reward 是否等于 100000。
          - 而使用索引下推后，判断记录的 reward 是否等于 100000 的工作交给了存储引擎层，过程如下 ：
            - Server 层首先调用存储引擎的接口定位到满足查询条件的第一条二级索引记录，也就是定位到 age > 20 的第一条记录；
            - 存储引擎定位到二级索引后，先不执行回表操作，而是先判断一下该索引中包含的列（reward列）的条件（reward 是否等于 100000）是否成立。如果条件不成立，则直接跳过该二级索引。如果成立，则执行回表操作，将完成记录返回给 Server 层。
            - Server 层在判断其他的查询条件（本次查询没有其他条件）是否成立，如果成立则将其发送给客户端；否则跳过该记录，然后向存储引擎索要下一条记录。
            - 如此往复，直到存储引擎把表中的所有记录读完。
          - 可以看到，使用了索引下推后，虽然 reward 列无法使用到联合索引，但是因为它包含在联合索引（age，reward）里，所以直接在存储引擎过滤出满足 reward = 100000 的记录后，才去执行回表操作获取整个记录。相比于没有使用索引下推，节省了很多回表操作。
          - 当你发现执行计划里的 Extr 部分显示了 “Using index condition”，说明使用了索引下推。
    - 总结
      - 执行一条 SQL 查询语句，期间发生了什么？
        - 连接器：建立连接，管理连接、校验用户身份；
        - 查询缓存：查询语句如果命中查询缓存则直接返回，否则继续往下执行。MySQL 8.0 已删除该模块；
        - 解析 SQL，通过解析器对 SQL 查询语句进行词法分析、语法分析，然后构建语法树，方便后续模块读取表名、字段、语句类型；
        - 执行 SQL：执行 SQL 共有三个阶段： 
          - 预处理阶段：检查表或字段是否存在；将 select \* 中的 \* 符号扩展为表上的所有列。
          - 优化阶段：基于查询成本的考虑， 选择查询成本最小的执行计划； 
          - 执行阶段：根据执行计划执行 SQL 查询语句，从存储引擎读取记录，返回给客户端； 
  - Mysql一行记录是怎么存储的
    - MySQL 的数据存放在哪个文件？
      - 大家都知道 MySQL 的数据都是保存在磁盘的，那具体是保存在哪个文件呢？
      - MySQL 存储的行为是由存储引擎实现的，MySQL 支持多种存储引擎，不同的存储引擎保存的文件自然也不同。
      - InnoDB 是我们常用的存储引擎，也是 MySQL 默认的存储引擎。所以，本文主要以 InnoDB 存储引擎展开讨论。
      - 先来看看 MySQL 数据库的文件存放在哪个目录？、
      - 我们每创建一个 database（数据库） 都会在 /var/lib/mysql/ 目录里面创建一个以 database 为名的目录，然后保存表结构和表数据的文件都会存放在这个目录里。
      - 比如，我这里有一个名为 my_test 的 database，该 database 里有一张名为 t_order 数据库表。
      #image("Screenshot_20250821_151010.png")
      - 可以看到，共有三个文件，这三个文件分别代表着：
        - db.opt，用来存储当前数据库的默认字符集和字符校验规则。
        - t_order.frm ，t_order 的表结构会保存在这个文件。在 MySQL 中建立一张表都会生成一个.frm 文件，该文件是用来保存每个表的元数据信息的，主要包含表结构定义。
        - t_order.ibd，t_order 的表数据会保存在这个文件。表数据既可以存在共享表空间文件（文件名：ibdata1）里，也可以存放在独占表空间文件文件名：表名字.ibd）。这个行为是由参数 innodb_file_per_table 控制的，若设置了参数 innodb_file_per_table 为 1，则会将存储的数据、索引等信息单独存储在一个独占表空间，从 MySQL 5.6.6 版本开始，它的默认值就是 1 了，因此从这个版本之后， MySQL 中每一张表的数据都存放在一个独立的 .ibd 文件。
    - 表空间文件的结构是怎么样的？
      - 表空间由段（segment）、区（extent）、页（page）、行（row）组成，InnoDB存储引擎的逻辑存储结构大致如下图：
      #image("Screenshot_20250821_151508.png")
      + 行
        - 数据库表中的记录都是按行（row）进行存放的，每行记录根据不同的行格式，有不同的存储结构。后面我们详细介绍 InnoDB 存储引擎的行格式，也是本文重点介绍的内容。
      + 页
        - 记录是按照行来存储的，但是数据库的读取并不以「行」为单位，否则一次读取（也就是一次 I/O 操作）只能处理一行数据，效率会非常低。因此，InnoDB 的数据是按「页」为单位来读写的，也就是说，当需要读一条记录的时候，并不是将这个行记录从磁盘读出来，而是以页为单位，将其整体读入内存。默认每个页的大小为 16KB，也就是最多能保证 16KB 的连续存储空间。
        - 页是 InnoDB 存储引擎磁盘管理的最小单元，意味着数据库每次读写都是以 16KB 为单位的，一次最少从磁盘中读取 16K 的内容到内存中，一次最少把内存中的 16K 内容刷新到磁盘中。
        - 页的类型有很多，常见的有数据页、undo 日志页、溢出页等等。
      + 区
        - 我们知道 InnoDB 存储引擎是用 B+ 树来组织数据的。B+ 树中每一层都是通过双向链表连接起来的，如果是以页为单位来分配存储空间，那么链表中相邻的两个页之间的物理位置并不是连续的，可能离得非常远，那么磁盘查询时就会有大量的随机I/O，随机 I/O 是非常慢的。
        - 解决这个问题也很简单，就是让链表中相邻的页的物理位置也相邻，这样就可以使用顺序 I/O 了，那么在范围查询（扫描叶子节点）的时候性能就会很高。
        - 那具体怎么解决呢？
          - 在表中数据量大的时候，为某个索引分配空间的时候就不再按照页为单位分配了，而是按照区（extent）为单位分配。每个区的大小为 1MB，对于 16KB 的页来说，连续的 64 个页会被划为一个区，这样就使得链表中相邻的页的物理位置也相邻，就能使用顺序 I/O 了。
        - 简单来说，区是innodb在分配空间时提前划分一块连续的物理空间来存放页
      + 段
        - 表空间是由各个段（segment）组成的，段是由多个区（extent）组成的。段一般分为数据段、索引段和回滚段等。
          - 索引段：存放 B + 树的非叶子节点的区的集合；
          - 数据段：存放 B + 树的叶子节点的区的集合；
          - 回滚段：存放的是回滚数据的区的集合，之前讲事务隔离 (opens new window)的时候就介绍到了 MVCC 利用了回滚段实现了多版本查询数据。
     - InnoDB 行格式有哪些？
       - 行格式（row_format），就是一条记录的存储结构。
       - InnoDB 提供了 4 种行格式，分别是 Redundant、Compact、Dynamic和 Compressed 行格式。
         - Redundant 是很古老的行格式了，MySQL 5.0 版本之前用的行格式，现在基本没人用了。
         - 由于 Redundant 不是一种紧凑的行格式，所以 MySQL 5.0 之后引入了 Compact 行记录存储方式，Compact 是一种紧凑的行格式，设计的初衷就是为了让一个数据页中可以存放更多的行记录，从 MySQL 5.1 版本之后，行格式默认设置成 Compact。
         - Dynamic 和 Compressed 两个都是紧凑的行格式，它们的行格式都和 Compact 差不多，因为都是基于 Compact 改进一点东西。从 MySQL5.7 版本之后，默认使用 Dynamic 行格式。
        -  COMPACT 行格式长什么样？
          - #image("Screenshot_20250821_162038.png")
          - 可以看到，一条完整的记录分为「记录的额外信息」和「记录的真实数据」两个部分。
          - 记录的额外信息
            - 记录的额外信息包含 3 个部分：变长字段长度列表、NULL 值列表、记录头信息。
              + 变长字段长度列表
                - varchar(n) 和 char(n) 的区别是什么，相信大家都非常清楚，char 是定长的，varchar 是变长的，变长字段实际存储的数据的长度（大小）不固定的。
                - 所以，在存储数据的时候，也要把数据占用的大小存起来，存到「变长字段长度列表」里面，读取数据的时候才能根据这个「变长字段长度列表」去读取对应长度的数据。其他 TEXT、BLOB 等变长字段也是这么实现的。
                - 为了展示「变长字段长度列表」具体是怎么保存「变长字段的真实数据占用的字节数」，我们先创建这样一张表，字符集是 ascii（所以每一个字符占用的 1 字节），行格式是 Compact，t_user 表中 name 和 phone 字段都是变长字段：
                #image("Screenshot_20250821_162352.png")
                - 这些变长字段的真实数据占用的字节数会按照列的顺序逆序存放（等下会说为什么要这么设计），所以「变长字段长度列表」里的内容是「 03 01」，而不是 「01 03」。
                - 同样的道理，我们也可以得出第二条记录的行格式中，「变长字段长度列表」里的内容是「 04 02」
                - 第三条记录中 phone 列的值是 NULL，NULL 是不会存放在行格式中记录的真实数据部分里的，所以「变长字段长度列表」里不需要保存值为 NULL 的变长字段的长度。
            - 为什么「变长字段长度列表」的信息要按照逆序存放？
              - 这个设计是有想法的，主要是因为「记录头信息」中指向下一个记录的指针，指向的是下一条记录的「记录头信息」和「真实数据」之间的位置，这样的好处是向左读就是记录头信息，向右读就是真实数据，比较方便。
              - 「变长字段长度列表」中的信息之所以要逆序存放，是因为这样可以使得位置靠前的记录的真实数据和数据对应的字段长度信息可以同时在一个 CPU Cache Line 中，这样就可以提高 CPU Cache 的命中率。
              - 同样的道理， NULL 值列表的信息也需要逆序存放。
              #image("Screenshot_20250821_212119.png")
              #image("Screenshot_20250821_212127.png")
              - 个人认为可这样理解[11][3] [abc][hello world]在这个存放顺序里，11前面有一个指针，world后面有一个指针，现在读到长度为11就可直接读到helloworld
            - 每个数据库表的行格式都有「变长字段字节数列表」吗？
              - 其实变长字段字节数列表不是必须的。
              - 当数据表没有变长字段的时候，比如全部都是 int 类型的字段，这时候表里的行格式就不会有「变长字段长度列表」了，因为没必要，不如去掉以节省空间。
          - NUll 值列表
            - 表中的某些列可能会存储 NULL 值，如果把这些 NULL 值都放到记录的真实数据中会比较浪费空间，所以 Compact 行格式把这些值为 NULL 的列存储到 NULL值列表中。
            - 如果存在允许 NULL 值的列，则每个列对应一个二进制位（bit），二进制位按照列的顺序逆序排列。
              - 二进制位的值为1时，代表该列的值为NULL。
              - 二进制位的值为0时，代表该列的值不为NULL。
            - 另外，NULL 值列表必须用整数个字节的位表示（1字节8位），如果使用的二进制位个数不足整数个字节，则在字节的高位补 0。
            #image("Screenshot_20250821_212419.png")
            #image("Screenshot_20250821_212431.png")
            #image("Screenshot_20250821_212445.png")
            #image("Screenshot_20250821_212453.png")
            #image("Screenshot_20250821_212511.png")
            - 每个数据库表的行格式都有「NULL 值列表」吗？
              - NULL 值列表也不是必须的。
              - 当数据表的字段都定义成 NOT NULL 的时候，这时候表里的行格式就不会有 NULL 值列表了。
              - 所以在设计数据库表的时候，通常都是建议将字段设置为 NOT NULL，这样可以至少节省 1 字节的空间（NULL 值列表至少占用 1 字节空间）。
            - 「NULL 值列表」是固定 1 字节空间吗？如果这样的话，一条记录有 9 个字段值都是 NULL，这时候怎么表示？
              - 「NULL 值列表」的空间不是固定 1 字节的。
              - 当一条记录有 9 个字段值都是 NULL，那么就会创建 2 字节空间的「NULL 值列表」，以此类推。
          - 记录头信息
            - delete_mask ：标识此条数据是否被删除。从这里可以知道，我们执行 detele 删除记录的时候，并不会真正的删除记录，只是将这个记录的 delete_mask 标记为 1。
            - next_record：下一条记录的位置。从这里可以知道，记录与记录之间是通过链表组织的。在前面我也提到了，指向的是下一条记录的「记录头信息」和「真实数据」之间的位置，这样的好处是向左读就是记录头信息，向右读就是真实数据，比较方便。
            - record_type：表示当前记录的类型，0表示普通记录，1表示B+树非叶子节点记录，2表示最小记录，3表示最大记录
        - 记录的真实数据
          - 记录真实数据部分除了我们定义的字段，还有三个隐藏字段，分别为：row_id、trx_id、roll_pointer，我们来看下这三个字段是什么。
            - row_id
              - 如果我们建表的时候指定了主键或者唯一约束列，那么就没有 row_id 隐藏字段了。如果既没有指定主键，又没有唯一约束，那么 InnoDB 就会为记录添加 row_id 隐藏字段。row_id不是必需的，占用 6 个字节。
            - trx_id
              - 事务id，表示这个数据是由哪个事务生成的。 trx_id是必需的，占用 6 个字节。
            - roll_pointer
              - 这条记录上一个版本的指针。roll_pointer 是必需的，占用 7 个字节。
              - 与MVCC有关
        - varchar(n) 中 n 最大取值为多少？
          - 我们要清楚一点，MySQL 规定除了 TEXT、BLOBs 这种大对象类型之外，其他所有的列（不包括隐藏列和记录头信息）占用的字节长度加起来不能超过 65535 个字节。
          - 也就是说，一行记录除了 TEXT、BLOBs 类型的列，限制最大为 65535 字节，注意是一行的总长度，不是一列。
          - 知道了这个前提之后，我们再来看看这个问题：「varchar(n) 中 n 最大取值为多少？」
          - varchar(n) 字段类型的 n 代表的是最多存储的字符数量，并不是字节大小哦。
          - 要算 varchar(n) 最大能允许存储的字节数，还要看数据库表的字符集，因为字符集代表着，1个字符要占用多少字节，比如 ascii 字符集， 1 个字符占用 1 字节，那么 varchar(100) 意味着最大能允许存储 100 字节的数据。
        - 单字段的情况
          - 前面我们知道了，一行记录最大只能存储 65535 字节的数据。
          - 那假设数据库表只有一个 varchar(n) 类型的列且字符集是 ascii，在这种情况下， varchar(n) 中 n 最大取值是 65535 吗？
          - 我们定义一个 varchar(65535) 类型的字段，字符集为 ascii 的数据库表。
          #image("Screenshot_20250822_154232.png")
          - 这是因为我们存储字段类型为 varchar(n) 的数据时，其实分成了三个部分来存储：
            - 真实数据
            - 真实数据占用的字节数
            - NULL 标识，如果不允许为NULL，这部分不需要
          - 本次案例中，「NULL 值列表」所占用的字节数是多少？
            - 前面我创建表的时候，字段是允许为 NULL 的，所以会用 1 字节来表示「NULL 值列表」。
          - 本次案例中，「变长字段长度列表」所占用的字节数是多少？
            「变长字段长度列表」所占用的字节数 = 所有「变长字段长度」占用的字节数之和。
            - 所以，我们要先知道每个变长字段的「变长字段长度」需要用多少字节表示？
              - 条件一：如果变长字段允许存储的最大字节数小于等于 255 字节，就会用 1 字节表示「变长字段长度」；
              - 条件二：如果变长字段允许存储的最大字节数大于 255 字节，就会用 2 字节表示「变长字段长度」；
            - 我们这里字段类型是 varchar(65535) ，字符集是 ascii，所以代表着变长字段允许存储的最大字节数是 65535，符合条件二，所以会用 2 字节来表示「变长字段长度」。
            - 因为我们这个案例是只有 1 个变长字段，所以「变长字段长度列表」= 1 个「变长字段长度」占用的字节数，也就是 2 字节。
            - 因为我们在算 varchar(n) 中 n 最大值时，需要减去 「变长字段长度列表」和 「NULL 值列表」所占用的字节数的。所以，在数据库表只有一个 varchar(n) 字段且字符集是 ascii 的情况下，varchar(n) 中 n 最大值 = 65535 - 2 - 1 = 65532。
            - 在 UTF-8 字符集下，一个字符最多需要三个字节，varchar(n) 的 n 最大取值就是 65532/3 = 21844。上面所说的只是针对于一个字段的计算方式。
            #image("Screenshot_20250822_155216.png")
        - 多字段的情况
          - 如果有多个字段的话，要保证所有字段的长度 + 变长字段字节数列表所占用的字节数 + NULL值列表所占用的字节数 <= 65535。
      - 行溢出后，MySQL 是怎么处理的？
        - MySQL 中磁盘和内存交互的基本单位是页，一个页的大小一般是 16KB，也就是 16384字节，而一个 varchar(n) 类型的列最多可以存储 65532字节，一些大对象如 TEXT、BLOB 可能存储更多的数据，这时一个页可能就存不了一条记录。这个时候就会发生行溢出，多的数据就会存到另外的「溢出页」中。
        - 如果一个数据页存不了一条记录，InnoDB 存储引擎会自动将溢出的数据存放到「溢出页」中。在一般情况下，InnoDB 的数据都是存放在 「数据页」中。但是当发生行溢出时，溢出的数据会存放到「溢出页」中。
        - 当发生行溢出时，在记录的真实数据处只会保存该列的一部分数据，而把剩余的数据放在「溢出页」中，然后真实数据处用 20 字节存储指向溢出页的地址，从而可以找到剩余数据所在的页。大致如下图所示。
        #image("Screenshot_20250822_155012.png")
        #image("Screenshot_20250822_155355.png")
+ 索引篇
  - 什么是索引？
    - 数据库中，索引的定义就是帮助存储引擎快速获取数据的一种数据结构，形象的说就是索引是数据的目录。
    - 所谓的存储引擎，说白了就是如何存储数据、如何为存储的数据建立索引和如何更新、查询数据等技术的实现方法。
    - MySQL 存储引擎有 MyISAM 、InnoDB、Memory，其中 InnoDB 是在 MySQL 5.5 之后成为默认的存储引擎。
  - 索引的分类
    - 你知道索引有哪些吗？大家肯定都能霹雳啪啦地说出聚簇索引、主键索引、二级索引、普通索引、唯一索引、hash索引、B+树索引等等。
    - 然后再问你，你能将这些索引分一下类吗？可能大家就有点模糊了。其实，要对这些索引进行分类，要清楚这些索引的使用和实现方式，然后再针对有相同特点的索引归为一类。
    - 我们可以按照四个角度来分类索引。
      - 按「数据结构」分类：B+tree索引、Hash索引、Full-text索引。
      - 按「物理存储」分类：聚簇索引（主键索引）、二级索引（辅助索引）。
      - 按「字段特性」分类：主键索引、唯一索引、普通索引、前缀索引。
      - 按「字段个数」分类：单列索引、联合索引。
    - 按数据结构分类
      - 常见的存储引擎 InnoDB、MyISAM 和 Memory 分别支持的索引类型。
      #image("Screenshot_20250822_160926.png")
      - InnoDB 是在 MySQL 5.5 之后成为默认的 MySQL 存储引擎，B+Tree 索引类型也是 MySQL 存储引擎采用最多的索引类型。
      - 在创建表时，InnoDB 存储引擎会根据不同的场景选择不同的列作为索引：
        - 如果有主键，默认会使用主键作为聚簇索引的索引键（key）；
        - 如果没有主键，就选择第一个不包含 NULL 值的唯一列作为聚簇索引的索引键（key）；
        - 在上面两个都没有的情况下，InnoDB 将自动生成一个隐式自增 id 列作为聚簇索引的索引键（key）；
        - 其它索引都属于辅助索引（Secondary Index），也被称为二级索引或非聚簇索引。创建的主键索引和二级索引默认使用的是 B+Tree 索引。
      - 行数据，存储在 B+Tree 索引时是长什么样子的？
        - B+Tree 是一种多叉树，叶子节点才存放数据，非叶子节点只存放索引，而且每个节点里的数据是按主键顺序存放的。每一层父节点的索引值都会出现在下层子节点的索引值中，因此在叶子节点中，包括了所有的索引值信息，并且每一个叶子节点都有两个指针，分别指向下一个叶子节点和上一个叶子节点，形成一个双向链表。
        #image("Screenshot_20250822_161340.png")
      - 通过主键查询商品数据的过程
        #image("Screenshot_20250822_161448.png")
      - 通过二级索引查询商品数据的过程
        #image("Screenshot_20250822_161557.png")
        - 回表
          - 二级索引查到主键后，再通过主键索引找数据，这个过程叫「回表」，也就是说要查两个 B+Tree 才能查到数据。
        - 覆盖索引
          - 这种在二级索引的 B+Tree 就能查询到结果的过程就叫作「覆盖索引」，也就是只需要查一个 B+Tree 就能找到数据。
        #image("Screenshot_20250822_161620.png")
      -  为什么 MySQL InnoDB 选择 B+tree 作为索引的数据结构？
        - 前面已经讲了 B+Tree 的索引原理，现在就来回答一下 B+Tree 相比于 B 树、二叉树或 Hash 索引结构的优势在哪儿？
        + B+Tree vs B Tree
          - B+Tree 只在叶子节点存储数据，而 B 树 的非叶子节点也要存储数据，所以 B+Tree 的单个节点的数据量更小，在相同的磁盘 I/O 次数下，就能查询更多的节点。
          - 另外，B+Tree 叶子节点采用的是双链表连接，适合 MySQL 中常见的基于范围的顺序查找，而 B 树无法做到这一点。
        + B+Tree vs 二叉树
          - 对于有 N 个叶子节点的 B+Tree，其搜索复杂度为O(logdN)，其中 d 表示节点允许的最大子节点个数为 d 个。
          - 在实际的应用当中， d 值是大于100的，这样就保证了，即使数据达到千万级别时，B+Tree 的高度依然维持在 3~4 层左右，也就是说一次数据查询操作只需要做 3~4 次的磁盘 I/O 操作就能查询到目标数据。
          - 而二叉树的每个父节点的儿子节点个数只能是 2 个，意味着其搜索复杂度为 O(logN)，这已经比 B+Tree 高出不少，因此二叉树检索到目标数据所经历的磁盘 I/O 次数要更多。
        + B+Tree vs Hash
          - Hash 在做等值查询的时候效率贼快，搜索复杂度为 O(1)。
          - 但是 Hash 表不适合做范围查询，它更适合做等值的查询，这也是 B+Tree 索引要比 Hash 表索引有着更广泛的适用场景的原因。
    - 按物理存储分类 
      - 从物理存储的角度来看，索引分为聚簇索引（主键索引）、二级索引（辅助索引）。
      - 这两个区别在前面也提到了：
        - 主键索引的 B+Tree 的叶子节点存放的是实际数据，所有完整的用户记录都存放在主键索引的 B+Tree 的叶子节点里；
        - 二级索引的 B+Tree 的叶子节点存放的是主键值，而不是实际数据。
      - 所以，在查询时使用了二级索引，如果查询的数据能在二级索引里查询的到，那么就不需要回表，这个过程就是覆盖索引。如果查询的数据不在二级索引里，就会先检索二级索引，找到对应的叶子节点，获取到主键值后，然后再检索主键索引，就能查询到数据了，这个过程就是回表。
    - 按字段特性分类
      - 从字段特性的角度来看，索引分为主键索引、唯一索引、普通索引、前缀索引。
      - 主键索引
        - 主键索引就是建立在主键字段上的索引，通常在创建表的时候一起创建，一张表最多只有一个主键索引，索引列的值不允许有空值。
        - 创建主键索引的方式
        #image("Screenshot_20250822_162351.png")
      - 唯一索引
        - 唯一索引建立在 UNIQUE 字段上的索引，一张表可以有多个唯一索引，索引列的值必须唯一，但是允许有空值。
        - 创建唯一索引
        #image("Screenshot_20250822_162429-1.png")
      - 普通索引
        - 普通索引就是建立在普通字段上的索引，既不要求字段为主键，也不要求字段为 UNIQUE。
        - 创建普通索引
        #image("Screenshot_20250822_162522.png")
      - 前缀索引
        - 前缀索引是指对字符类型字段的前几个字符建立的索引，而不是在整个字段上建立的索引，前缀索引可以建立在字段类型为 char、 varchar、binary、varbinary 的列上。
        - 使用前缀索引的目的是为了减少索引占用的存储空间，提升查询效率。
        - 创建前缀索引
        #image("Screenshot_20250822_162618.png")
    - 按字段个数分类
      - 从字段个数的角度来看，索引分为单列索引、联合索引（复合索引）。
        - 建立在单列上的索引称为单列索引，比如主键索引；
        -     建立在多列上的索引称为联合索引；
      - 联合索引
        - 通过将多个字段组合成一个索引，该索引就被称为联合索引。
        - 创建联合索引
        #image("Screenshot_20250822_163428.png")
          - 可以看到，联合索引的非叶子节点用两个字段的值作为 B+Tree 的 key 值。当在联合索引查询数据时，先按 product_no 字段比较，在 product_no 相同的情况下再按 name 字段比较。
          - 也就是说，联合索引查询的 B+Tree 是先按 product_no 进行排序，然后再 product_no 相同的情况再按 name 字段排序。
          - 因此，使用联合索引时，存在最左匹配原则，也就是按照最左优先的方式进行索引的匹配。在使用联合索引进行查询的时候，如果不遵循「最左匹配原则」，联合索引会失效，这样就无法利用到索引快速查询的特性了。
          - 比如，如果创建了一个 (a, b, c) 联合索引，如果查询条件是以下这几种，就可以匹配上联合索引：
            - where a=1；
            - where a=1 and b=2 and c=3；
            - where a=1 and b=2；
          - 需要注意的是，因为有查询优化器，所以 a 字段在 where 子句的顺序并不重要。
          - 但是，如果查询条件是以下这几种，因为不符合最左匹配原则，所以就无法匹配上联合索引，联合索引就会失效:
            - where b=2；
            - where c=3；
            - where b=2 and c=3；
          - 上面这些查询条件之所以会失效，是因为(a, b, c) 联合索引，是先按 a 排序，在 a 相同的情况再按 b 排序，在 b 相同的情况再按 c 排序。所以，b 和 c 是全局无序，局部相对有序的，这样在没有遵循最左匹配原则的情况下，是无法利用到索引的。
            - 举例
            #image("Screenshot_20250822_163732.png")
        - 联合索引范围查询
          - 联合索引有一些特殊情况，并不是查询过程使用了联合索引查询，就代表联合索引中的所有字段都用到了联合索引进行索引查询，也就是可能存在部分字段用到联合索引的 B+Tree，部分字段没有用到联合索引的 B+Tree 的情况。
          - 这种特殊情况就发生在范围查询。联合索引的最左匹配原则会一直向右匹配直到遇到「范围查询」就会停止匹配。也就是范围查询的字段可以用到联合索引，但是在范围查询字段的后面的字段无法用到联合索引。
          - 范围查询有很多种，那到底是哪些范围查询会导致联合索引的最左匹配原则会停止匹配呢？
          - 接下来，举例几个范围查例子。
            - select \* from t_table where a > 1 and b = 2，联合索引（a, b）哪一个字段用到了联合索引的 B+Tree？
              - 由于联合索引（二级索引）是先按照 a 字段的值排序的，所以符合 a > 1 条件的二级索引记录肯定是相邻，于是在进行索引扫描的时候，可以定位到符合 a > 1 条件的第一条记录，然后沿着记录所在的链表向后扫描，直到某条记录不符合 a > 1 条件位置。所以 a 字段可以在联合索引的 B+Tree 中进行索引查询。
              - 但是在符合 a > 1 条件的二级索引记录的范围里，b 字段的值是无序的。比如前面图的联合索引的 B+ Tree 里，下面这三条记录的 a 字段的值都符合 a > 1 查询条件，而 b 字段的值是无序的：
                - a 字段值为 5 的记录，该记录的 b 字段值为 8；
                - a 字段值为 6 的记录，该记录的 b 字段值为 10；
                - a 字段值为 7 的记录，该记录的 b 字段值为 5；
              - 因此，我们不能根据查询条件 b = 2 来进一步减少需要扫描的记录数量（b 字段无法利用联合索引进行索引查询的意思）。
              - 所以在执行这条查询语句的时候，对应的扫描区间是 (2, + ∞)，形成该扫描区间的边界条件是 a > 1，与 b = 2 无关。
              - 因此，Q1 这条查询语句只有 a 字段用到了联合索引进行索引查询，而 b 字段并没有使用到联合索引。
              - 我们也可以在执行计划中的 key_len 知道这一点，在使用联合索引进行查询的时候，通过 key_len 我们可以知道优化器具体使用了多少个字段的搜索条件来形成扫描区间的边界条件。
              #image("Screenshot_20250822_164336.png")
            - select \* from t_table where a >= 1 and b = 2，联合索引（a, b）哪一个字段用到了联合索引的 B+Tree？
              - Q2 和 Q1 的查询语句很像，唯一的区别就是 a 字段的查询条件「大于等于」。
              - 由于联合索引（二级索引）是先按照 a 字段的值排序的，所以符合 >= 1 条件的二级索引记录肯定是相邻，于是在进行索引扫描的时候，可以定位到符合 >= 1 条件的第一条记录，然后沿着记录所在的链表向后扫描，直到某条记录不符合 a>= 1 条件位置。所以 a 字段可以在联合索引的 B+Tree 中进行索引查询。
              - 虽然在符合 a>= 1 条件的二级索引记录的范围里，b 字段的值是「无序」的，但是对于符合 a = 1 的二级索引记录的范围里，b 字段的值是「有序」的（因为对于联合索引，是先按照 a 字段的值排序，然后在 a 字段的值相同的情况下，再按照 b 字段的值进行排序）。
              - 于是，在确定需要扫描的二级索引的范围时，当二级索引记录的 a 字段值为 1 时，可以通过 b = 2 条件减少需要扫描的二级索引记录范围（b 字段可以利用联合索引进行索引查询的意思）。也就是说，从符合 a = 1 and b = 2 条件的第一条记录开始扫描，而不需要从第一个 a 字段值为 1 的记录开始扫描。
              - 所以，Q2 这条查询语句 a 和 b 字段都用到了联合索引进行索引查询。
              #image("Screenshot_20250822_164528.png")
            - SELECT \* FROM t_table WHERE a BETWEEN 2 AND 8 AND b = 2，联合索引（a, b）哪一个字段用到了联合索引的 B+Tree？
              - Q3 查询条件中 a BETWEEN 2 AND 8 的意思是查询 a 字段的值在 2 和 8 之间的记录。不同的数据库对 BETWEEN ... AND 处理方式是有差异的。在 MySQL 中，BETWEEN 包含了 value1 和 value2 边界值，类似于 >= and =<。而有的数据库则不包含 value1 和 value2 边界值（类似于 > and <）。
              - 这里我们只讨论 MySQL。由于 MySQL 的 BETWEEN 包含 vvalue1 和 value2 边界值，所以类似于 Q2 查询语句，因此 Q3 这条查询语句 a 和 b 字段都用到了联合索引进行索引查询。
              #image("Screenshot_20250822_165258.png")
            - SELECT \* FROM t_user WHERE name like 'j%' and age = 22，联合索引（name, age）哪一个字段用到了联合索引的 B+Tree？
              - 由于联合索引（二级索引）是先按照 name 字段的值排序的，所以前缀为 ‘j’ 的 name 字段的二级索引记录都是相邻的， 于是在进行索引扫描的时候，可以定位到符合前缀为 ‘j’ 的 name 字段的第一条记录，然后沿着记录所在的链表向后扫描，直到某条记录的 name 前缀不为 ‘j’ 为止。
              - 所以 a 字段可以在联合索引的 B+Tree 中进行索引查询，形成的扫描区间是['j','k')。注意， j 是闭区间。如下图：
              #image("Screenshot_20250822_165604.png")
              - 虽然在符合前缀为 ‘j’ 的 name 字段的二级索引记录的范围里，age 字段的值是「无序」的，但是对于符合 name = j 的二级索引记录的范围里，age字段的值是「有序」的（因为对于联合索引，是先按照 name 字段的值排序，然后在 name 字段的值相同的情况下，再按照 age 字段的值进行排序）。
              - 于是，在确定需要扫描的二级索引的范围时，当二级索引记录的 name 字段值为 ‘j’ 时，可以通过 age = 22 条件减少需要扫描的二级索引记录范围（age 字段可以利用联合索引进行索引查询的意思）。也就是说，从符合 name = 'j' and age = 22 条件的第一条记录时开始扫描，而不需要从第一个 name 为 j 的记录开始扫描 。如下图的右边：
              - 所以，Q4 这条查询语句 a 和 b 字段都用到了联合索引进行索引查询。
              #image("Screenshot_20250822_165922.png")
            - 综上所示，联合索引的最左匹配原则，在遇到范围查询（如 >、<）的时候，就会停止匹配，也就是范围查询的字段可以用到联合索引，但是在范围查询字段的后面的字段无法用到联合索引。注意，对于 >=、<=、BETWEEN、like 前缀匹配的范围查询，并不会停止匹配，前面我也用了四个例子说明了。
      - 索引下推
        - 现在我们知道，对于联合索引（a, b），在执行 select \* from table where a > 1 and b = 2 ,语句的时候，只有 a 字段能用到索引，那在联合索引的 B+Tree 找到第一个满足条件的主键值（ID 为 2）后，还需要判断其他条件是否满足（看 b 是否等于 2），那是在联合索引里判断？还是回主键索引去判断呢？
        - 在 MySQL 5.6 之前，只能从 ID2 （主键值）开始一个个回表，到「主键索引」上找出数据行，再对比 b 字段值。
        - 而 MySQL 5.6 引入的索引下推优化（index condition pushdown)，可以在联合索引遍历过程中，对联合索引中包含的字段先做判断，直接过滤掉不满足条件的记录，减少回表次数。
        - 当你的查询语句的执行计划里，出现了 Extra 为 Using index condition，那么说明使用了索引下推的优化。
      - 索引区分度
        - 另外，建立联合索引时的字段顺序，对索引效率也有很大影响。越靠前的字段被用于索引过滤的概率越高，实际开发工作中建立联合索引时，要把区分度大的字段排在前面，这样区分度大的字段越有可能被更多的 SQL 使用到。
        #image("Screenshot_20250822_204723.png")
      - 联合索引进行排序
        - 针对下面这条 SQL，你怎么通过索引来提高查询效率呢？

        select \* from order where status =1 order by create_time asc

        - 有的同学会认为，单独给 status 建立一个索引就可以了。
        - 但是更好的方式给 status 和 create_time 列建立一个联合索引，因为这样可以避免 MySQL 数据库发生文件排序。
        - 因为在查询时，如果只用到 status 的索引，但是这条语句还要对 create_time 排序，这时就要用文件排序 filesort，也就是在 SQL 执行计划中，Extra 列会出现 Using filesort。
        - 所以，要利用索引的有序性，在 status 和 create_time 列建立联合索引，这样根据 status 筛选后的数据就是按照 create_time 排好序的，避免在文件排序，提高了查询效率。
        - 文件排序
          - 指 MySQL 在无法利用索引完成排序时，采用的一种额外的排序操作。
          #image("Screenshot_20250822_205701.png")
      -  什么时候需要 / 不需要创建索引？
        - 索引最大的好处是提高查询速度，但是索引也是有缺点的，比如
          - 需要占用物理空间，数量越大，占用空间越大；
          - 创建索引和维护索引要耗费时间，这种时间随着数据量的增加而增大；
          - 会降低表的增删改的效率，因为每次增删改索引，B+ 树为了维护索引有序性，都需要进行动态维护。
        -  什么时候适用索引？
          - 字段有唯一性限制的，比如商品编码；
          - 经常用于 WHERE 查询条件的字段，这样能够提高整个表的查询速度，如果查询条件不是一个字段，可以建立联合索引。
          - 经常用于 GROUP BY 和 ORDER BY 的字段，这样在查询的时候就不需要再去做一次排序了，因为我们都已经知道了建立索引之后在 B+Tree 中的记录都是排序好的。
        - 什么时候不需要创建索引？
          - WHERE 条件，GROUP BY，ORDER BY 里用不到的字段，索引的价值是快速定位，如果起不到定位的字段通常是不需要创建索引的，因为索引是会占用物理空间的。
          - 字段中存在大量重复数据，不需要创建索引，比如性别字段，只有男女，如果数据库表中，男女的记录分布均匀，那么无论搜索哪个值都可能得到一半的数据。在这些情况下，还不如不要索引，因为 MySQL 还有一个查询优化器，查询优化器发现某个值出现在表的数据行中的百分比很高的时候，它一般会忽略索引，进行全表扫描。
          - 表数据太少的时候，不需要创建索引；
          - 经常更新的字段不用创建索引，比如不要对电商项目的用户余额建立索引，因为索引字段频繁修改，由于要维护 B+Tree的有序性，    那么就需要频繁的重建索引，这个过程是会影响数据库性能的。
      - 有什么优化索引的方法？
        - 这里说一下几种常见优化索引的方法：
          - 前缀索引优化；
            - 前缀索引顾名思义就是使用某个字段中字符串的前几个字符建立索引，那我们为什么需要使用前缀来建立索引呢？
            - 使用前缀索引是为了减小索引字段大小，可以增加一个索引页中存储的索引值，有效提高索引的查询速度。在一些大字符串的字段作为索引时，使用前缀索引可以帮助我们减小索引项的大小。
            - 不过，前缀索引有一定的局限性，例如：
              - order by 就无法使用前缀索引；
              - 无法把前缀索引用作覆盖索引；
          - 覆盖索引优化；
            - 覆盖索引是指 SQL 中 query 的所有字段，在索引 B+Tree 的叶子节点上都能找得到的那些索引，从二级索引中查询得到记录，而不需要通过聚簇索引查询获得，可以避免回表的操作。
            - 假设我们只需要查询商品的名称、价格，有什么方式可以避免回表呢？
            - 我们可以建立一个联合索引，即「商品ID、名称、价格」作为一个联合索引。如果索引中存在这些数据，查询将不会再次检索主键索引，从而避免回表。
            - 所以，使用覆盖索引的好处就是，不需要查询出包含整行记录的所有信息，也就减少了大量的 I/O 操作。
          - 主键索引最好是自增的；
            - InnoDB 创建主键索引默认为聚簇索引，数据被存放在了B+Tree 的叶子节点上。也就是说，同一个叶子节点内的各个数据是按主键顺序存放的，因此，每当有一条新的数据插入时，数据库会根据主键将其插入到对应的叶子节点中。
            - 如果我们使用自增主键，那么每次插入的新数据就会按顺序添加到当前索引节点的位置，不需要移动已有的数据，当页面写满，就会自动开辟一个新页面。因为每次插入一条新记录，都是追加操作，不需要重新移动数据，因此这种插入数据的方法效率非常高。
            - 如果我们使用非自增主键，由于每次插入主键的索引值都是随机的，因此每次插入新的数据时，就可能会插入到现有数据页中间的某个位置，这将不得不移动其它数据来满足新数据的插入，甚至需要从一个页面复制数据到另外一个页面，我们通常将这种情况称为页分裂。页分裂还有可能会造成大量的内存碎片，导致索引结构不紧凑，从而影响查询效率。
            #image("Screenshot_20250822_211807.png")
            #image("Screenshot_20250822_211903.png")
            #image("Screenshot_20250822_211915.png")
            - 主键字段长度越小，意味着二级索引的叶子节点越小（二级索引的叶子节点存放的数据是主键值），这样二级索引占用的空间也就越小。
          - 索引最好设置为 NOT NULL
            - 为了更好的利用索引，索引列要设置为 NOT NULL 约束。有两个原因：
              - 第一原因：索引列存在 NULL 就会导致优化器在做索引选择的时候更加复杂，更加难以优化，因为可为 NULL 的列会使索引、索引统计和值比较都更复杂，比如进行索引统计时，count 会省略值为NULL 的行。
              - 第二个原因：NULL 值是一个没意义的值，但是它会占用物理空间，所以会带来的存储空间的问题，因为 InnoDB 存储记录的时候，如果表中存在允许为 NULL 的字段，那么行格式 (opens new window)中至少会用 1 字节空间存储 NULL 值列表，如下图的紫色部分：
          - 防止索引失效；
            - 用上了索引并不意味着查询的时候会使用到索引，所以我们心里要清楚有哪些情况会导致索引失效，从而避免写出索引失效的查询语句，否则这样的查询效率是很低的。
            - 发生索引失效的情况：
              - 当我们使用左或者左右模糊匹配的时候，也就是 like %xx 或者like %xx%这两种方式都会造成索引失效；
              - 当我们在查询条件中对索引列做了计算、函数、类型转换操作，这些情况下都会造成索引失效；
              - 联合索引要能正确使用需要遵循最左匹配原则，也就是按照最左优先的方式进行索引的匹配，否则就会导致索引失效。
              - 在 WHERE 子句中，如果在 OR 前的条件列是索引列，而在 OR 后的条件列不是索引列，那么索引会失效。
              #image("Screenshot_20250822_214000.png")
              #image("Screenshot_20250822_214040.png")
              #image("Screenshot_20250822_214156.png")
              #image("Screenshot_20250822_214254.png")
              #image("Screenshot_20250822_214542.png")
              #image("Screenshot_20250822_215418.png")
              - 实际过程中，可能会出现其他的索引失效场景，这时我们就需要查看执行计划，通过执行计划显示的数据判断查询语句是否使用了索引。

              #image("Screenshot_20250822_212440.png")
              - 在这些情况里，all 是最坏的情况，因为采用了全表扫描的方式。index 和 all 差不多，只不过 index 对索引表进行全扫描，这样做的好处是不再需要对数据进行排序，但是开销依然很大。所以，要尽量避免全表扫描和全索引扫描。
              - range 表示采用了索引范围扫描，一般在 where 子句中使用 < 、>、in、between 等关键词，只检索给定范围的行，属于范围查找。从这一级别开始，索引的作用会越来越明显，因此我们需要尽量让 SQL 查询可以使用到 range 这一级别及以上的 type 访问方式。
              - ref 类型表示采用了非唯一索引，或者是唯一索引的非唯一性前缀，返回数据返回可能是多条。因为虽然使用了索引，但该索引列的值并不唯一，有重复。这样即使使用索引快速查找到了第一条数据，仍然不能停止，要进行目标值附近的小范围扫描。但它的好处是它并不需要扫全表，因为索引是有序的，即便有重复值，也是在一个非常小的范围内扫描。
              - eq_ref 类型是使用主键或唯一索引时产生的访问方式，通常使用在多表联查中。比如，对两张表进行联查，关联条件是两张表的 user_id 相等，且 user_id 是唯一索引，那么使用 EXPLAIN 进行执行计划查看的时候，type 就会显示 eq_ref。
              - const 类型表示使用了主键或者唯一索引与常量值进行比较，比如 select name from product where id=1。
              - 需要说明的是 const 类型和 eq_ref 都使用了主键或唯一索引，不过这两个类型有所区别，const 是与常量进行比较，查询效率会更快，而 eq_ref 通常用于多表联查中。
            - 除了关注 type，我们也要关注 extra 显示的结果。
              - Using filesort ：当查询语句中包含 group by 操作，而且无法利用索引完成排序操作的时候， 这时不得不选择相应的排序算法进行，甚至可能会通过文件排序，效率是很低的，所以要避免这种问题的出现。
              - Using temporary：使了用临时表保存中间结果，，MySQL 在对查询结果排序时使用临时表，常见于排序 order by 和分组查询 group by。效率低，要避免这种问题的出现。
              - Using index：所需数据只需在索引即可全部获得，不须要再到表中取数据    ，也就是使用了覆盖索引，避免了回表操作，效率不错。
  - 从数据页的角度看B+树
    - 数据页包括七个部分
     #image("Screenshot_20250822_220419.png")
    - 在 File Header 中有两个指针，分别指向上一个数据页和下一个数据页，连接起来的页相当于一个双向的链表
    #image("Screenshot_20250822_220503.png")
    - 采用链表的结构是让数据页之间不需要是物理上的连续的，而是逻辑上的连续。
    - 数据页的主要作用是存储记录，也就是数据库的数据，所以重点说一下数据页中的 User Records 是怎么组织数据的。
    - 数据页中的记录按照「主键」顺序组成单向链表，单向链表的特点就是插入、删除非常方便，但是检索效率不高，最差的情况下需要遍历链表上的所有节点才能完成检索。
    - 因此，数据页中有一个页目录，起到记录的索引作用。
    - 那 InnoDB 是如何给记录创建页目录的呢？
    #image("Screenshot_20250822_220636.png")
    - 页目录创建的过程如下：
      + 将所有的记录划分成几个组，这些记录包括最小记录和最大记录，但不包括标记为“已删除”的记录；
      + 每个记录组的最后一条记录就是组内最大的那条记录，并且最后一条记录的头信息中会存储该组一共有多少条记录，作为 n_owned 字段（上图中粉红色字段）
      + 页目录用来存储每组最后一条记录的地址偏移量，这些地址偏移量会按照先后顺序存储起来，每组的地址偏移量也被称之为槽（slot），每个槽相当于指针指向了不同组的最后一个记录。
      - 从图可以看到，页目录就是由多个槽组成的，槽相当于分组记录的索引。然后，因为记录是按照「主键值」从小到大排序的，所以我们通过槽查找记录时，可以使用二分法快速定位要查询的记录在哪个槽（哪个记录分组），定位到槽后，再遍历槽内的所有记录，找到对应的记录，无需从最小记录开始遍历整个页中的记录链表。
      - 例子
      #image("Screenshot_20250822_221849.png")
    -  B+ 树是如何进行查询的？
      - 当我们需要存储大量的记录时，就需要多个数据页，这时我们就需要考虑如何建立合适的索引，才能方便定位记录所在的页。
      - 为了解决这个问题，InnoDB 采用了 B+ 树作为索引。磁盘的 I/O 操作次数对索引的使用效率至关重要，因此在构造索引的时候，我们更倾向于采用“矮胖”的 B+ 树数据结构，这样所需要进行的磁盘 I/O 次数更少，而且 B+ 树 更适合进行关键字的范围查询。
      - 通过上图，我们看出 B+ 树的特点：
        - 只有叶子节点（最底层的节点）才存放了数据，非叶子节点（其他上层节）仅用来存放目录项作为索引。
        - 非叶子节点分为不同层次，通过分层来降低每一层的搜索量；
        - 所有节点按照索引键大小排序，构成一个双向链表，便于范围查询；
      - #image("Screenshot_20250823_102856.png")
    - 聚簇索引和二级索引
      - 聚簇索引的叶子节点存放的是实际数据，所有完整的用户记录都存放在聚簇索引的叶子节点；
      - 二级索引的叶子节点存放的是主键值，而不是实际数据。
    - 因为表的数据都是存放在聚簇索引的叶子节点里，所以 InnoDB 存储引擎一定会为表创建一个聚簇索引，且由于数据在物理上只会保存一份，所以聚簇索引只能有一个。
    - InnoDB 在创建聚簇索引时，会根据不同的场景选择不同的列作为索引：
      - 如果有主键，默认会使用主键作为聚簇索引的索引键；
      - 没有主键，就选择第一个不包含 NULL 值的唯一列作为聚簇索引的索引键；
      - 在上面两个都没有的情况下，InnoDB 将自动生成一个隐式自增 id 列作为聚簇索引的索引键；
    - 一张表只能有一个聚簇索引，那为了实现非主键字段的快速搜索，就引出了二级索引（非聚簇索引/辅助索引），它也是利用了 B+ 树的数据结构，但是二级索引的叶子节点存放的是主键值，不是实际数据。
  - 为什么 MySQL 采用 B+ 树作为索引？
    - 怎样的索引的数据结构是好的？
      - MySQL 的数据是持久化的，意味着数据（索引+记录）是保存到磁盘上的，因为这样即使设备断电了，数据也不会丢失。
      - 内存的访问速度是纳秒级别的，而磁盘访问的速度是毫秒级别的，也就是说读取同样大小的数据，磁盘中读取的速度比从内存中读取的速度要慢上万倍，甚至几十万倍。
      - 磁盘读写的最小单位是扇区，扇区的大小只有 512B 大小，操作系统一次会读写多个扇区，所以操作系统的最小读写单位是块（Block）。Linux 中的块大小为 4KB，也就是一次磁盘 I/O 操作会直接读写 8 个扇区。
      - 由于数据库的索引是保存到磁盘上的，因此当我们通过索引查找某行数据的时候，就需要先从磁盘读取索引到内存，再通过索引从磁盘中找到某行数据，然后读入到内存，也就是说查询过程中会发生多次磁盘 I/O，而磁盘 I/O 次数越多，所消耗的时间也就越大。
      - 所以，我们希望索引的数据结构能在尽可能少的磁盘的 I/O 操作中完成查询工作
      - 另外，MySQL 是支持范围查找的，所以索引的数据结构不仅要能高效地查询某一个记录，而且也要能高效地执行范围查找。
      - 所以，要设计一个适合 MySQL 索引的数据结构，至少满足以下要求：
        - 能在尽可能少的磁盘的 I/O 操作中完成查询工作；
        - 要能高效地查询某一个记录，也要能高效地执行范围查找；
    - 什么是二分查找树？
      - 用数组来实现线性排序的数据虽然简单好用，但是插入新元素的时候性能太低。
      - 因为插入一个元素，需要将这个元素之后的所有元素后移一位，如果这个操作发生在磁盘中呢？这必然是灾难性的。因为磁盘的速度比内存慢几十万倍，所以我们不能用一种线性结构将磁盘排序。
      - 其次，有序的数组在使用二分查找的时候，每次查找都要不断计算中间的位置。
      - 那我们能不能设计一个非线形且天然适合二分查找的数据结构呢？
      - 找到所有二分查找中用到的所有中间节点，把他们用指针连起来，并将最中间的节点作为根节点。这样就变成一个二叉查找树。
      - 二叉查找树的特点是一个节点的左子树的所有节点都小于这个节点，右子树的所有节点都大于这个节点，
      - 这样我们在查询数据时，不需要计算中间节点的位置了，只需将查找的数据与节点的数据进行比较。
      - 另外，二叉查找树解决了插入新节点的问题，因为二叉查找树是一个跳跃结构，不必连续排列。这样在插入的时候，新节点可以放在任何位置，不会像线性结构那样插入一个元素，所有元素都需要向后排列。
      - 二叉查找树存在一个极端情况，会导致它变成一个瘸子！当每次插入的元素都是二叉查找树中最大的元素，二叉查找树就会退化成了一条链表，查找数据的时间复杂度变成了 O(n)
      - 而且会随着插入的元素越多，树的高度也变高，意味着需要磁盘 IO 操作的次数就越多，这样导致查询性能严重下降，再加上不能范围查询，所以不适合作为数据库的索引结构。
    - 什么是自平衡二叉树？
      - 主要是在二叉查找树的基础上增加了一些条件约束：每个节点的左子树和右子树的高度差不能超过 1。也就是说节点的左子树和右子树仍然为平衡二叉树，这样查询操作的时间复杂度就会一直维持在 O(logn) 。
      - 不管平衡二叉查找树还是红黑树，都会随着插入的元素增多，而导致树的高度变高，这就意味着磁盘 I/O 操作次数多，会影响整体数据查询的效率。
    - 什么是 B 树
      - 为了解决降低树的高度的问题，后面就出来了 B 树，它不再限制一个节点就只能有 2 个子节点，而是允许 M 个子节点 (M>2)，从而降低树的高度。
      - 但是 B 树的每个节点都包含数据（索引+记录），而用户的记录数据的大小很有可能远远超过了索引数据，这就需要花费更多的磁盘 I/O 操作次数来读到「有用的索引数据」。
      - 而且，在我们查询位于底层的某个节点（比如 A 记录）过程中，「非 A 记录节点」里的记录数据会从磁盘加载到内存，但是这些记录数据是没用的，我们只是想读取这些节点的索引数据来做比较查询，而「非 A 记录节点」里的记录数据对我们是没用的，这样不仅增多磁盘 I/O 操作次数，也占用内存资源。
      - 另外，如果使用 B 树来做范围查询的话，需要使用中序遍历，这会涉及多个节点的磁盘 I/O 问题，从而导致整体速度下降。
    - 什么是 B+ 树？
      - B+ 树与 B 树差异的点，主要是以下这几点：
        - 叶子节点（最底部的节点）才会存放实际数据（索引+记录），非叶子节点只会存放索引；
        - 所有索引都会在叶子节点出现，叶子节点之间构成一个有序链表；
        - 非叶子节点的索引也会同时存在在子节点中，并且是在子节点中所有索引的最大（或最小）。
        - 非叶子节点中有多少个子节点，就有多少个索引；
      - 下面通过三个方面，比较下 B+ 和 B 树的性能区别。
        + 单点查询
          - B 树进行单个索引查询时，最快可以在 O(1) 的时间代价内就查到，而从平均时间代价来看，会比 B+ 树稍快一些。
          - 但是 B 树的查询波动会比较大，因为每个节点即存索引又存记录，所以有时候访问到了非叶子节点就可以找到索引，而有时需要访问到叶子节点才能找到索引。
          - B+ 树的非叶子节点不存放实际的记录数据，仅存放索引，因此数据量相同的情况下，相比存储即存索引又存记录的 B 树，B+树的非叶子节点可以存放更多的索引，因此 B+ 树可以比 B 树更「矮胖」，查询底层节点的磁盘 I/O次数会更少。
        + 插入和删除效率
          - B+ 树有大量的冗余节点，这样使得删除一个节点的时候，可以直接从叶子节点中删除，甚至可以不动非叶子节点，这样删除非常快，
          - 注意，：B+ 树对于非叶子节点的子节点和索引的个数，定义方式可能会有不同，有的是说非叶子节点的子节点的个数为 M 阶，而索引的个数为 M-1（这个是维基百科里的定义），因此我本文关于 B+ 树的动图都是基于这个。但是我在前面介绍 B 树与 B+ 树的差异时，说的是「非叶子节点中有多少个子节点，就有多少个索引」，主要是 MySQL 用到的 B+ 树就是这个特性。
          - B 树没有冗余节点，删除节点的时候非常复杂，比如删除根节点中的数据，可能涉及复杂的树的变形
          - B+ 树的插入也是一样，有冗余节点，插入可能存在节点的分裂（如果节点饱和），但是最多只涉及树的一条路径。而且 B+ 树会自动平衡，不需要像更多复杂的算法
        + 范围查询
          - B 树和 B+ 树等值查询原理基本一致，先从根节点查找，然后对比目标数据的范围，最后递归的进入子节点查找。
          - 因为 B+ 树所有叶子节点间还有一个链表进行连接，这种设计对范围查找非常有帮助。比如说我们想知道 12 月 1 日和 12 月 12 日之间的订单，这个时候可以先查找到 12 月 1 日所在的叶子节点，然后利用链表向右遍历，直到找到 12 月12 日的节点，这样就不需要从根节点查询了，进一步节省查询需要的时间。
          - 而 B 树没有将所有叶子节点用链表串联起来的结构，因此只能通过树的遍历来完成范围查询，这会涉及多个节点的磁盘 I/O 操作，范围查询效率不如 B+ 树。
     - MySQL 中的 B+ 树
       - Innodb 使用的 B+ 树有一些特别的点，比如：
         - B+ 树的叶子节点之间是用「双向链表」进行连接，这样的好处是既能向右遍历，也能向左遍历。
         - B+ 树节点内容是数据页，数据页里存放了用户的记录以及各种信息，每个数据页默认大小是 16 KB。
       - Innodb 根据索引类型不同，分为聚簇和二级索引。他们区别在于：
         - 聚簇索引的叶子节点存放的是实际数据，所有完整的用户记录都存放在聚簇索引的叶子节点
         - 而二级索引的叶子节点存放的是主键值，而不是实际数据。
  - MySQL 单表不要超过 2000W 行，靠谱吗？
    - select (\@i:=\@i+1) as rownum, person_name from person, (select \@i:=100) as init; set \@i=1;
    - 表空间
      - 这张表数据，在硬盘上存储也是类似如此的，它实际是放在一个叫 person.ibd （innodb data）的文件中，也叫做表空间；虽然数据表中，他们看起来是一条连着一条，但是实际上在文件中它被分成很多小份的数据页，而且每一份都是 16K。
    - 页的数据结构
      - 一个 InnoDB 数据页的存储空间大致被划分成了 7 个部分，有的部分占用的字节数是确定的，有的部分占用的字节数是不确定的。
      - 在页的 7 个组成部分中，我们自己存储的记录会按照我们指定的行格式存储到 User Records 部分。
      - 但是在一开始生成页的时候，其实并没有 User Records 这个部分，每当我们插入一条记录，都会从 Free Space 部分，也就是尚未使用的存储空间中申请一个记录大小的空间划分到 User Records 部分。
      - 当 Free Space 部分的空间全部被 User Records 部分替代掉之后，也就意味着这个页使用完了，如果还有新的记录插入的话，就需要去申请新的页了。
      - 假如我们需要查找一条记录，我们可以把表空间中的每一页都加载到内存中，然后对记录挨个判断是不是我们想要的。在数据量小的时候，没啥问题，内存也可以撑。但是现实就是这么残酷，不会给你这个局面。为了解决这问题，MySQL 中就有了索引的概念
    - 索引的数据结构
      - 在 MySQL 中索引的数据结构和刚刚描述的页几乎是一模一样的，而且大小也是 16K,。
      - 但是在索引页中记录的是页 (数据页，索引页) 的最小主键 id 和页号，以及在索引页中增加了层级的信息，从 0 开始往上算，所以页与页之间就有了上下层级的概念。
      - 我们是单拿一个节点来看，首先它是一个非叶子节点（索引页），在它的内容区中有 id 和 页号地址两部分：
        - id ：对应页中记录的最小记录 id 值；
        - 页号：地址是指向对应页的指针；
    - 单表建议值
      - 同样一个 16K 的页，非叶子节点里的每条数据都指向新的页，而新的页有两种可能
        - 如果是叶子节点，那么里面就是一行行的数据
        - 如果是非叶子节点的话，那么就会继续指向新的页
      - 假设
        - 非叶子节点内指向其他页的数量为 x
        - 叶子节点内能容纳的数据行数为 y
        - B+ 树的层数为 z
          - Total =x^(z-1) \*y 也就是说总数会等于 x 的 z-1 次方 与 Y 的乘积。
          #image("Screenshot_20250823_112324.png")
        - 在保持相同的层级（相似查询性能）的情况下，在行数据大小不同的情况下，其实这个最大建议值也是不同的，而且影响查询性能的还有很多其他因素，比如，数据库版本，服务器配置，sql 的编写等等。
        - MySQL 为了提高性能，会将表的索引装载到内存中，在 InnoDB buffer size 足够的情况下，其能完成全加载进内存，查询不会有问题。
        - 但是，当单表数据库到达某个量级的上限时，导致内存无法存储其索引，使得之后的 SQL 查询会产生磁盘 IO，从而导致性能下降，所以增加硬件配置（比如把内存当磁盘使），可能会带来立竿见影的性能提升哈。
  - count(\*) 和 count(1) 有什么区别？哪个性能最好？
    - 哪种 count 性能最好？
      - count() 是什么？
        - count() 是一个聚合函数，函数的参数不仅可以是字段名，也可以是其他任意表达式，该函数作用是统计符合查询条件的记录中，函数指定的参数不为 NULL 的记录有多少个。
        - select count(1) from t_order;这条语句是统计「 t_order 表中，1 这个表达式不为 NULL 的记录」有多少个。1 这个表达式就是单纯数字，它永远都不是 NULL，所以上面这条语句， 其实是在统计 t_order 表中有多少个记录。
      - count(主键字段) 执行过程是怎样的？
        - count(主键字段) 执行过程是怎样的？
        - server 层会循环向 InnoDB 读取一条记录，如果 count 函数指定的参数不为 NULL,那么就会将变量 count 加 1，直到符合查询的全部记录被读完，就退出循环。最后将 count 变量的值发送给客户端。  
        - 如果表里只有主键索引，没有二级索引时，那么，InnoDB 循环遍历聚簇索引，将读取到的记录返回给 server 层，然后读取记录中的 id 值，就会 id 值判断是否为 NULL，如果不为 NULL，就将 count 变量加 1。
        - 但是，如果表里有二级索引时，InnoDB 循环遍历的对象就不是聚簇索引，而是二级索引。这是因为相同数量的二级索引记录可以比聚簇索引记录占用更少的存储空间，所以二级索引树比聚簇索引树小，这样遍历二级索引的 I/O 成本比遍历聚簇索引的 I/O 成本小，因此「优化器」优先选择的是二级索引。
      - count(1) 执行过程是怎样的？
        - 如果表里只有主键索引，没有二级索引时。InnoDB 循环遍历聚簇索引（主键索引），将读取到的记录返回给 server 层，但是不会读取记录中的任何字段的值，因为 count 函数的参数是 1，不是字段，所以不需要读取记录中的字段值。参数 1 很明显并不是 NULL，因此 server 层每从 InnoDB 读取到一条记录，就将 count 变量加 1。
        - 可以看到，count(1) 相比 count(主键字段) 少一个步骤，就是不需要读取记录中的字段值，所以通常会说 count(1) 执行效率会比 count(主键字段) 高一点。
        - 但是，如果表里有二级索引时，InnoDB 循环遍历的对象就二级索引了。
      - count(\*) 执行过程是怎样的？
        - 看到 \* 这个字符的时候，是不是大家觉得是读取记录中的所有字段值？
        - 对于 selete \* 这条语句来说是这个意思，但是在 count(\*) 中并不是这个意思。
        - count(\*) 其实等于 count(0)，也就是说，当你使用 count(\*) 时，MySQL 会将 \* 参数转化为参数 0 来处理。
        - 所以，count(\*) 执行过程跟 count(1) 执行过程基本一样的，性能没有什么差异。
        - 而且 MySQL 会对 count(\*) 和 count(1) 有个优化，如果有多个二级索引的时候，优化器会使用key_len 最小的二级索引进行扫描。
        - 只有当没有二级索引的时候，才会采用主键索引来进行统计。
      -  count(字段) 执行过程是怎样的？
        - count(字段) 的执行效率相比前面的 count(1)、 count(\*)、 count(主键字段) 执行效率是最差的。
        -  name不是索引，普通字段

          select count(name) from t_order;

        - 对于这个查询来说，会采用全表扫描的方式来计数，所以它的执行效率是比较差的。如果你非要统计表中该字段不为 NULL 的记录个数，建议给这个字段建立一个二级索引。
        #image("Screenshot_20250823_144458.png")
    - 为什么要通过遍历的方式来计数？
      - 你可能会好奇，为什么 count 函数需要通过遍历的方式来统计记录个数？
      - 我前面将的案例都是基于 Innodb 存储引擎来说明的，但是在 MyISAM 存储引擎里，执行 count 函数的方式是不一样的，通常在没有任何查询条件下的 count(\*)，MyISAM 的查询速度要明显快于 InnoDB。
      - 使用 MyISAM 引擎时，执行 count 函数只需要 O(1 )复杂度，这是因为每张 MyISAM 的数据表都有一个 meta 信息有存储了row_count值，由表级锁保证一致性，所以直接读取 row_count 值就是 count 函数的执行结果。
      - 而 InnoDB 存储引擎是支持事务的，同一个时刻的多个查询，由于多版本并发控制（MVCC）的原因，InnoDB 表“应该返回多少行”也是不确定的，所以无法像 MyISAM一样，只维护一个 row_count 变量。
      #image("Screenshot_20250823_145545.png")  
    - 如何优化 count(\*)？
      - 如果对一张大表经常用 count(\*) 来做统计，其实是很不好的。
      - 比如下面我这个案例，表 t_order 共有 1200+ 万条记录，我也创建了二级索引，但是执行一次 select count(\*) from t_order 要花费差不多 5 秒！  
      - 面对大表的记录统计，我们有没有什么其他更好的办法呢？
        + 近似值
          - 如果你的业务对于统计个数不需要很精确，比如搜索引擎在搜索关键词的时候，给出的搜索结果条数是一个大概值。
          - 这时，我们就可以使用 show table status 或者 explain 命令来表进行估算。
          - 执行 explain 命令效率是很高的，因为它并不会真正的去查询，下图中的 rows 字段值就是 explain 命令对表 t_order 记录的估算值。
        + 额外表保存计数值
          - 如果是想精确的获取表的记录总数，我们可以将这个计数值保存到单独的一张计数表中。
          - 当我们在数据表插入一条记录的同时，将计数表中的计数字段 + 1。也就是说，在新增和删除操作时，我们需要额外维护这个计数表。
  - MySQL 分页有什么性能问题？怎么优化？
    - 我们刷网站的时候，我们经常会遇到需要分页查询的场景。
    - id是主键，并且在user_name建了个非主键索引
    - 为了实现分页。很容易联想到下面这样的sql语句。
      select \* from page order by id limit offset, size;
    - 比如一页有10条数据。
      - 第一页就是下面这样的sql语句。
        - select \* from page order by id limit 0, 10;
      - 第一百页就是
        - select \* from page order by id limit 990, 10;
      - 用这种方式，同样都是拿10条数据，查第一页和第一百页的查询速度是一样的吗？为什么？
    - 两种limit的执行过程
      - 上面的两种查询方式。对应 limit offset, size 和 limit size 两种方式。
      - 而其实 limit size ，相当于 limit 0, size。也就是从0开始取size条数据。也就是说，两种方式的区别在于offset是否为0。
      - 我们先来看下limit sql的内部执行逻辑。
      #image("Screenshot_20250823_151337.png")
      - mysql内部分为server层和存储引擎层。一般情况下存储引擎都用innodb。
      - server层有很多模块，其中需要关注的是执行器是用于跟存储引擎打交道的组件。
      - 执行器可以通过调用存储引擎提供的接口，将一行行数据取出，当这些数据完全符合要求（比如满足其他where条件），则会放到结果集中，最后返回给调用mysql的客户端（go、java写的应用程序）。
      - 我们可以对下面的sql先执行下 explain。
        - explain select \* from page order by id limit 0, 10;
        - 可以看到，explain中提示 key 那里，执行的是PRIMARY，也就是走的主键索引。
      - 基于主键索引的limit执行过程
        - server层会调用innodb的接口，由于这次的offset=6000000，会在innodb里的主键索引中获取到第0到（6000000 + 10）条完整行数据，会在innodb里的主键索引中获取到第0到（6000000 + 10）条完整行数据，，放到server层的结果集中，返回给客户端。
        - 可以看出，当offset非0时，server层会从引擎层获取到很多无用的数据，而获取的这些无用数据都是要耗时的。
        - 因此，我们就知道了文章开头的问题的答案，mysql查询中 limit 1000,10 会比 limit 10 更慢。原因是 limit 1000,10 会取出1000+10条数据，并抛弃前1000条，这部分耗时更大
        - 那这种case有办法优化吗？
        - 当select后面是\*号时，就需要拷贝完整的行信息，拷贝完整数据跟只拷贝行数据里的其中一两个列字段耗时是不同的，这就让原本就耗时的操作变得更加离谱。
        - 因为前面的offset条数据最后都是不要的，就算将完整字段都拷贝来了又有什么用呢，所以我们可以将sql语句修改成下面这样。

        select \* from page  where id >=(select id from page  order by id limit 6000000, 1) order by id limit 10;
        - 上面这条sql语句，里面先执行子查询select id from page order by id limit 6000000, 1, 这个操作，其实也是将在innodb中的主键索引中获取到6000000+1条数据，然后server层会抛弃前6000000条，只保留最后一条数据的id。
        - 但不同的地方在于，在返回server层的过程中，只会拷贝数据行内的id这一列，而不会拷贝数据行的所有列，当数据量较大时，这部分的耗时还是比较明显的。
        - 在拿到了上面的id之后，假设这个id正好等于6000000，那sql就变成了
          
          select \* from page  where id >=(6000000) order by id limit 10;
        - 这样innodb再走一次主键索引，通过B+树快速定位到id=6000000的行数据，时间复杂度是lg(n)，然后向后取10条数据。
        - 这样性能确实是提升了，亲测能快一倍左右，属于那种耗时从3s变成1.5s的操作。
      - 基于非主键索引的limit执行过程
        - select \* from page order by user_name  limit 0, 10
        - server层会调用innodb的接口，在innodb里的非主键索引中获取到第0条数据对应的主键id后，回表到主键索引中找到对应的完整行数据，然后返回给server层，server层将其放到结果集中，返回给客户端。
        - 而当offset>0时，且offset的值较小时，逻辑也类似，区别在于，offset>0时会丢弃前面的offset条数据。
        - 也就是说非主键索引的limit过程，比主键索引的limit过程，多了个回表的消耗。
        - 但当offset变得非常大时，比如600万，此时执行explain。
        - 可以看到type那一栏显示的是ALL，也就是全表扫描。
        - 这是因为server层的优化器，会在执行器执行sql语句前，判断下哪种执行计划的代价更小。
        - 很明显，优化器在看到非主键索引的600w次回表之后，摇了摇头，还不如全表一条条记录去判断算了，于是选择了全表扫描。
        - 因此，当limit offset过大时，非主键索引查询非常容易变成全表扫描。是真·性能杀手。
        - 这种情况也能通过一些方式去优化。比如
          
          select \* from page t1, (select id from page order by user_name limit 6000000, 100) t2  WHERE t1.id = t2.id;

        - 先走innodb层的user_name非主键索引取出id，因为只拿主键id，不需要回表，所以这块性能会稍微快点，在返回server层之后，同样抛弃前600w条数据，保留最后的100个id。然后再用这100个id去跟t1表做id匹配，此时走的是主键索引，将匹配到的100条行数据返回。这样就绕开了之前的600w条数据的回表。
        - 当然，跟上面的case一样，还是没有解决要白拿600w条数据然后抛弃的问题，这也是非常挫的优化。
      - 深度分页问题
        - 深度分页问题，是个很恶心的问题，恶心就恶心在，这个问题，它其实无解。
        - 不管你是用mysql还是es，你都只能通过一些手段去"减缓"问题的严重性。
        - 遇到这个问题，我们就该回过头来想想。为什么我们的代码会产生深度分页问题？它背后的原始需求是什么，我们可以根据这个做一些规避。
        - 如果你是想取出全表的数据
          - 有些需求是这样的，我们有一张数据库表，但我们希望将这个数据库表里的所有数据取出，异构到es，或者hive里，这时候如果直接执行select \* from page;
          - 因为数据量较大，mysql根本没办法一次性获取到全部数据，妥妥超时报错。于是不少mysql小白会通过limit offset size分页的形式去分批获取，刚开始都是好的，等慢慢地，哪天数据表变得奇大无比，就有可能出现前面提到的深度分页问题。
          - 这种场景是最好解决的。我们可以将所有的数据根据id主键进行排序，然后分批次取，将当前批次的最大id作为下次筛选的条件进行查询。
          - 这个操作，可以通过主键索引，每次定位到id在哪，然后往后遍历100个数据，这样不管是多少万的数据，查询性能都很稳定。
        -  如果是给用户做分页展示
          - 如果我们要做搜索或筛选类的页面的话，就别用mysql了，用es，并且也需要控制展示的结果数，比如一万以内，这样不至于让分页过深。
          - 如果因为各种原因，必须使用mysql。那同样，也需要控制下返回结果数量，比如数量1k以内。
          - 这样就能勉强支持各种翻页，跳页（比如突然跳到第6页然后再跳到第106页）。
          - 但如果能从产品的形式上就做成不支持跳页会更好，比如只支持上一页或下一页。
          - 这样我们就可以使用上面提到的start_id方式，采用分批获取，每批数据以start_id为起始位置。这个解法最大的好处是不管翻到多少页，查询速度永远稳定。
          - 把这个功能包装一下。变成像抖音那样只能上划或下划，专业点，叫瀑布流。
+ 事务篇
  - 事务隔离级别是怎么实现的？
    - 事务有哪些特性？
      - 原子性（Atomicity）：一个事务中的所有操作，要么全部完成，要么全部不完成，不会结束在中间某个环节，而且事务在执行过程中发生错误，会被回滚到事务开始前的状态，就像这个事务从来没有执行过一样，就好比买一件商品，购买成功时，则给商家付了钱，商品到手；购买失败时，则商品在商家手中，消费者的钱也没花出去。
      - 一致性（Consistency）：是指事务操作前和操作后，数据满足完整性约束，数据库保持一致性状态。比如，用户 A 和用户 B 在银行分别有 800 元和 600 元，总共 1400 元用户 A 给用户 B 转账 200 元，分为两个步骤，从 A 的账户扣除 200 元和对 B 的账户增加 200 元。一致性就是要求上述步骤操作后，最后的结果是用户 A 还有 600 元，用户 B 有 800 元，总共 1400 元，，而不会出现用户 A 扣除了 200 元，但用户 B 未增加的情况（该情况，用户 A 和 B 均为 600 元，总共 1200 元）。
      - 隔离性（Isolation）：数据库允许多个并发事务同时对其数据进行读写和修改的能力，隔离性可以防止多个事务并发执行时由于交叉执行而导致数据的不一致，因为多个事务同时使用相同的数据时，不会相互干扰，每个事务都有一个完整的数据空间，对其他并发事务是隔离的。也就是说，消费者购买商品这个事务，是不影响其他消费者购买的。
      - 持久性（Durability）：事务处理结束后，对数据的修改就是永久的，即便系统故障也不会丢失。
    - InnoDB 引擎通过什么技术来保证事务的这四个特性的呢？
      - 持久性是通过 redo log （重做日志）来保证的；
      - 原子性是通过 undo log（回滚日志） 来保证的；
      - 隔离性是通过 MVCC（多版本并发控制） 或锁机制来保证的；
      - 一致性则是通过持久性+原子性+隔离性来保证；
    -  并行事务会引发什么问题？
      - 脏读
      #image("Screenshot_20250825_104717.png")
      - 不可重复读
      #image("Screenshot_20250825_104904.png")
      - 幻读
      #image("Screenshot_20250825_104918.png")
    -  事务的隔离级别有哪些？
      - 读未提交：指一个事务还没提交时，它做的变更就能被其他事务看到；
      - 读提交：指一个事务提交之后，它做的变更才能被其他事务看到；
      - 可重复读：指一个事务执行过程中看到的数据，一直跟这个事务启动时看到的数据是一致的，MySQL InnoDB 引擎的默认隔离级别；
      - 串行化：会对记录加上读写锁，在多个事务对这条记录进行读写操作时，如果发生了读写冲突的时候，后访问的事务必须等前一个事务执行完成，才能继续执行；
    - 隔离级别解决并发问题
      #image("Screenshot_20250825_105436.png")
    - MySQL 在「可重复读」隔离级别下，可以很大程度上避免幻读现象的发生（不是完全）
      - 所以 MySQL 并不会使用「串行化」隔离级别来避免幻读现象的发生，因为使用「串行化」隔离级别会影响性能。
    - 针对快照读（普通 select 语句），是通过 MVCC 方式解决了幻读，因为可重复读隔离级别下，事务执行过程中看到的数据，一直跟这个事务启动时看到的数据是一致的，即使中途有其他事务插入了一条数据，是查询不出来这条数据的，所以就很好了避免幻读问题。
    - 针对当前读（select ... for update 等语句），是通过 next-key lock（记录锁+间隙锁）方式解决了幻读，因为当执行 select ... for update 语句的时候，会加上 next-key lock，如果有其他事务在 next-key lock 锁范围内插入了一条记录，那么这个插入语句就会被阻塞，无法成功插入，所以就很好了避免幻读问题。
    - 这四种隔离级别具体是如何实现的呢？
      - 对于「读未提交」隔离级别的事务来说，因为可以读到未提交事务修改的数据，所以直接读取最新的数据就好了；
      - 对于「串行化」隔离级别的事务来说，通过加读写锁的方式来避免并行访问；
      - 对于「读提交」和「可重复读」隔离级别的事务来说，它们是通过 Read View （从一个「已提交版本」的快照中读取数据）来实现的，它们的区别在于创建 Read View 的时机不同，大家可以把 Read View 理解成一个数据快照，就像相机拍照那样，定格某一时刻的风景。「读提交」隔离级别是在「每个语句执行前」都会重新生成一个 Read View，而「可重复读」隔离级别是「启动事务时」生成一个 Read View，然后整个事务期间都在用这个 Read View。
    - 注意，执行「开始事务」命令，并不意味着启动了事务。  在 MySQL 有两种开启事务的命令，分别是：
      - begin/start transaction 命令；
      - start transaction with consistent snapshot 命令；
    - 这两种开启事务的命令，事务的启动时机是不同的：
      - 执行了 begin/start transaction 命令后，并不代表事务启动了。只有在执行这个命令后，执行了第一条 select 语句，才是事务真正启动的时机；
      - 只有在执行这个命令后，执行了第一条 select 语句，才是事务真正启动的时机；
    - Read View 在 MVCC 里如何工作的？
      - read view是什么 
      #image("Screenshot_20250825_110712.png")
      - 隐藏列
      #image("Screenshot_20250825_110934.png")
      - 版本链
      #image("Screenshot_20250825_111039.png")
    -  可重复读是如何工作的？
      - 可重复读隔离级别是启动事务时生成一个 Read View，然后整个事务期间都在用这个 Read View。
      - 事务A，B启动，假设a事务id是51,b是52
      - 那么原先版本数据的事务id就是50
      - b先读数据，发现50小于活跃事务id的最小值(在b的readview里是51,52，在a是51)
      - 接着，事务 A 通过 update 语句将这条记录修改了（还未提交事务）这时 MySQL 会记录相应的 undo log，并以链表的方式串联起来，形成版本链
      - #image("Screenshot_20250825_111650.png")
      - 然后事务 B 第二次去读取该记录，发现这条记录的 trx_id 值为 51，在事务 B 的 Read View 的 min_trx_id 和 max_trx_id 之间，则需要判断 trx_id 值是否在 m_ids 范围内，判断的结果是在的，那么说明这条记录是被还未提交的事务修改的，这时事务 B 并不会读取这个版本的记录。而是沿着 undo log 链条往下找旧版本的记录，直到找到 trx_id 「小于」事务 B 的 Read View 中的 min_trx_id 值的第一条记录，所以事务 B 能读取到的是 trx_id 为 50 的记录，也就是小林余额是 100 万的这条记录。最后，当事物 A 提交事务后，由于隔离级别时「可重复读」，所以事务 B 再次读取记录时，还是基于启动事务时创建的 Read View 来判断当前版本的记录是否可见。所以，即使事物 A 将小林余额修改为 200 万并提交了事务， 事务 B 第三次读取记录时，读到的记录都是小林余额是 100 万的这条记录。
    - 读提交是如何工作的？
      - 读提交隔离级别是在每次读取数据时，都会生成一个新的 Read View。
      - 也意味着，事务期间的多次读取同一条数据，前后两次读的数据可能会出现不一致，因为可能这期间另外一个事务修改了该记录，并提交了事务。
      - 情景
      #image("Screenshot_20250825_111859.png")
      - 我们来分析下为什么事务 B 第二次读数据时，读不到事务 A （还未提交事务）修改的数据？
        - 事务 B 在找到小林这条记录时，会看这条记录的 trx_id 是 51，在事务 B 的 Read View 的 min_trx_id 和 max_trx_id 之间，接下来需要判断 trx_id 值是否在 m_ids 范围内，判断的结果是在的，那么说明这条记录是被还未提交的事务修改的，这时事务 B 并不会读取这个版本的记录。沿着 undo log 链条往下找旧版本的记录，直到找到 trx_id 「小于」事务 B 的 Read View 中的 min_trx_id 值的第一条记录，所以事务 B 能读取到的是 trx_id 为 50 的记录
      - 我们来分析下为什么事务 A 提交后，事务 B 就可以读到事务 A 修改的数据？
        - 在事务 A 提交后，由于隔离级别是「读提交」，所以事务 B 在每次读数据的时候，会重新创建 Read View
        - 因为事务a提交了，所以活跃id只剩下52
        - 而数据库中记录为51,事务 B 在找到小林这条记录时，会发现这条记录的 trx_id 是 51，比事务 B 的 Read View 中的 min_trx_id 值（52）还小，这意味着修改这条记录的事务早就在创建 Read View 前提交过了，所以该版本的记录对事务 B 是可见的。
  - MySQL 可重复读隔离级别，完全解决幻读了吗？
    - 当前读是如何避免幻读的？
      - MySQL 里除了普通查询是快照读，其他都是当前读，比如 update、insert、delete，这些语句执行前都会查询最新版本的数据，然后再做进一步的操作。
      - 另外，select ... for update 这种查询语句是当前读，每次执行的时候都是读取最新的数据。
      - Innodb 引擎为了解决「可重复读」隔离级别使用「当前读」而造成的幻读问题，就引出了间隙锁。
      - 假设，表中有一个范围 id 为（3，5）间隙锁，那么其他事务就无法插入 id = 4 这条记录了
    - 幻读被完全解决了吗？
      - 可重复读隔离级别下虽然很大程度上避免了幻读，但是还是没有能完全解决幻读。
      - 举例一个可重复读隔离级别发生幻读现象的场景。
        - 第一个发生幻读现象的场景
          - #image("Screenshot_20250825_112843.png")
          - 其实就是update的读取现在数据的特性，在原来没有数据的情况下，另一个事务b插入的数据update也可以修改，并且因为update语句在事务a里，使得修改后的数据行的事务id变成事务a的id，而事务a的readview允许事务a的id的数据行被访问
        -  第二个发生幻读现象的场景
          #image("Screenshot_20250825_113052.png")
          - 也是利用update可以看到当前所有数据的特性
          - 要避免这类特殊场景下发生幻读的现象的话，就是尽量在开启事务之后，马上执行 select ... for update 这类当前读的语句，因为它会对记录加 next-key lock，从而避免其他事务插入一条新记录。
+ 锁篇
  - 根据加锁的范围，可以分为全局锁、表级锁和行锁三类。
  - 全局锁
    - 要使用全局锁，则要执行这条命令：flush tables with read lock
    - 执行后，整个数据库就处于只读状态了，这时其他线程执行以下操作，都会被阻塞：
      - 对数据的增删改操作，比如 insert、delete、update等语句；
      - 对表结构的更改操作，比如 alter table、drop table 等语句。
    - 如果要释放全局锁，则要执行这条命令：unlock tables
    - 当然，当会话断开了，全局锁会被自动释放。
    - 全局锁应用场景是什么？
      - 全局锁主要应用于做全库逻辑备份，这样在备份数据库期间，不会因为数据或表结构的更新，而出现备份文件的数据与预期的不一样。
      - 举个例子
      #image("Screenshot_20250825_155543.png")
      - 加全局锁又会带来什么缺点呢？
        - 加上全局锁，意味着整个数据库都是只读状态。
        - 那么如果数据库里有很多数据，备份就会花费很多的时间，关键是备份期间，业务只能读数据，而不能更新数据，这样会造成业务停滞。
      - 既然备份数据库数据的时候，使用全局锁会影响业务，那有什么其他方式可以避免？
        - 有的，如果数据库的引擎支持的事务支持可重复读的隔离级别，那么在备份数据库之前先开启事务，会先创建 Read View，然后整个事务执行期间都在用这个 Read View，而且由于 MVCC 的支持，备份期间业务依然可以对数据进行更新操作。
        - 因为在可重复读的隔离级别下，即使其他事务更新了表的数据，也不会影响备份数据库时的 Read View，这就是事务四大特性中的隔离性，这样备份期间备份的数据一直是在开启事务时的数据。
        - 备份数据库的工具是 mysqldump，在使用 mysqldump 时加上–single-transaction 参数的时候，就会在备份数据库之前先开启事务。这种方法只适用于支持「可重复读隔离级别的事务」的存储引擎。
        - InnoDB 存储引擎默认的事务隔离级别正是可重复读，因此可以采用这种方式来备份数据库。
        - 但是，对于 MyISAM 这种不支持事务的引擎，在备份数据库时就要使用全局锁的方法。
  - 表级锁
    - MySQL 表级锁有哪些？具体怎么用的。
      - 表锁；
        - 如果我们想对学生表（t_student）加表锁，可以使用下面的命令：
          - lock tables t_student read;
            - 允许当前会话读取被锁定的表，但阻止其他会话对这些表进行写操作。
          - lock tables t_stuent write;
            - 允许当前会话对表进行读写操作，但阻止其他会话对这些表进行任何操作（读或写）。
        - 需要注意的是，表锁除了会限制别的线程的读写外，也会限制本线程接下来的读写操作。
        - 举个例子， 如果在某个线程 A 中执行 lock tables t1 read, t2 write; 这个语句，则其他线程写 t1、读写 t2 的语句都会被阻塞。同时，线程 A 在执行 unlock tables 之前，也只能执行读 t1、读写 t2 的操作。连写 t1 都不允许，自然也不能访问其他表。
        - 要释放表锁，可以使用下面这条命令，会释放当前会话的所有表锁：unlock tables
        - 另外，当会话退出后，也会释放所有表锁。
        - 在还没有出现更细粒度的锁的时候，表锁是最常用的处理并发的方式，不过尽量避免在使用 InnoDB 引擎的表使用表锁，因为表锁的颗粒度太大，会影响并发性能，InnoDB 牛逼的地方在于实现了颗粒度更细的行级锁。
      - 元数据锁（MDL）;
        - 我们不需要显示的使用 MDL，因为当我们对数据库表进行操作时，会自动给这个表加上 MDL：
          - 对一张表进行 CRUD 操作时，加的是 MDL 读锁；
          - 对一张表做结构变更操作的时候，加的是 MDL 写锁；
        - MDL 是为了保证当用户对表执行 CRUD 操作时，防止其他线程对这个表结构做了变更。
        - 当有线程在执行 select 语句（ 加 MDL 读锁）的期间，如果有其他线程要更改该表的结构（ 申请 MDL 写锁），那么将会被阻塞，直到执行完 select 语句（ 释放 MDL 读锁）。
        - 反之，当有线程对表结构进行变更（ 加 MDL 写锁）的期间，如果有其他线程执行了 CRUD 操作（ 申请 MDL 读锁），那么就会被阻塞，直到表结构变更完成（ 释放 MDL 写锁）。
        - MDL 不需要显示调用，那它是在什么时候释放的?
          - MDL 是在事务提交后才会释放，这意味着事务执行期间，MDL 是一直持有的。
          - 那如果数据库有一个长事务（所谓的长事务，就是开启了事务，但是一直还没提交），那在对表结构做变更操作的时候，可能会发生意想不到的事情，比如下面这个顺序的场景：
            - 首先，线程 A 先启用了事务（但是一直不提交），然后执行一条 select 语句，此时就先对该表加上 MDL 读锁；
            - 然后，线程 B 也执行了同样的 select 语句，此时并不会阻塞，因为「读读」并不冲突；
            - 接着，线程 C 修改了表字段，此时由于线程 A 的事务并没有提交，也就是 MDL 读锁还在占用着，这时线程 C 就无法申请到 MDL 写锁，就会被阻塞，
            - 那么在线程 C 阻塞后，后续有对该表的 select 语句，就都会被阻塞，如果此时有大量该表的 select 语句的请求到来，就会有大量的线程被阻塞住，这时数据库的线程很快就会爆满了。
            - 为什么线程 C 因为申请不到 MDL 写锁，而导致后续的申请读锁的查询操作也会被阻塞？
              - 这是因为申请 MDL 锁的操作会形成一个队列，队列中写锁获取优先级高于读锁，一旦出现 MDL 写锁等待，会阻塞后续该表的所有 CRUD 操作。
              - 所以为了能安全的对表结构进行变更，在对表结构变更前，先要看看数据库中的长事务，是否有事务已经对表加上了 MDL 读锁，如果可以考虑 kill 掉这个长事务，然后再做表结构的变更。

      - 意向锁；
        - 在使用 InnoDB 引擎的表里对某些记录加上「共享锁」之前，需要先在表级别加上一个「意向共享锁」；
        - 在使用 InnoDB 引擎的表里对某些纪录加上「独占锁」之前，需要先在表级别加上一个「意向独占锁」；
        - 也就是，当执行插入、更新、删除操作，需要先对表加上「意向独占锁」，然后对该记录加独占锁。
        - 而普通的 select 是不会加行级锁的，普通的 select 语句是利用 MVCC 实现一致性读，是无锁的。
        - 不过，select 也是可以对记录加共享锁和独占锁的，具体方式如下：
          - select ... lock in share mode;先在表上加上意向共享锁，然后对读取的记录加共享锁
          - select ... for update;先表上加上意向独占锁，然后对读取的记录加独占锁                                                                                                                                           
        - 意向共享锁和意向独占锁是表级锁，不会和行级的共享锁和独占锁发生冲突，而且意向锁之间也不会发生冲突，只会和共享表锁（lock tables ... read）和独占表锁（lock tables ... write）发生冲突。
        - 表锁和行锁是满足读读共享、读写互斥、写写互斥的。如果没有「意向锁」，那么加「独占表锁」时，就需要遍历表里所有记录，查看是否有记录存在独占锁，这样效率会很慢。
        - 那么有了「意向锁」，由于在对记录加独占锁前，先会加上表级别的意向独占锁，那么在加「独占表锁」时，直接查该表是否有意向独占锁，如果有就意味着表里已经有记录被加了独占锁，这样就不用去遍历表里的记录。
        - 所以，意向锁的目的是为了快速判断表里是否有记录被加锁。
      - AUTO-INC 锁；
        - 表里的主键通常都会设置成自增的，这是通过对主键字段声明 AUTO_INCREMENT 属性实现的。
        - 之后可以在插入数据时，可以不指定主键的值，数据库会自动给主键赋值递增的值，这主要是通过 AUTO-INC 锁实现的。
        - AUTO-INC 锁是特殊的表锁机制，锁不是再一个事务提交后才释放，而是再执行完插入语句后就会立即释放。
        - 在插入数据时，会加一个表级别的 AUTO-INC 锁，然后为被 AUTO_INCREMENT 修饰的字段赋值递增的值，等插入语句执行完成后，才会把 AUTO-INC 锁释放掉。
        - 那么，一个事务在持有 AUTO-INC 锁的过程中，其他事务的如果要向该表插入语句都会被阻塞，从而保证插入数据时，被 AUTO_INCREMENT 修饰的字段的值是连续递增的。
        - 但是， AUTO-INC 锁再对大量数据进行插入的时候，会影响插入性能，因为另一个事务中的插入会被阻塞。
        - 因此， 在 MySQL 5.1.22 版本开始， InnoDB 存储引擎提供了一种轻量级的锁来实现自增。
        - 一样也是在插入数据的时候，会为被 AUTO_INCREMENT 修饰的字段加上轻量级锁，然后给该字段赋值一个自增的值，就把这个轻量级锁释放了，而不需要等待整个插入语句执行完后才释放锁。
        - InnoDB 存储引擎提供了个 innodb_autoinc_lock_mode 的系统变量，是用来控制选择用 AUTO-INC 锁，还是轻量级的锁。
          - 当 innodb_autoinc_lock_mode = 0，就采用 AUTO-INC 锁语句执行结束后才释放锁；
          - 当 innodb_autoinc_lock_mode = 2，就采用轻量级锁，申请自增主键后就释放锁，并不需要等语句执行后才释放。
          - 当 innodb_autoinc_lock_mode = 1： 
            - 普通 insert 语句，自增锁在申请之后就马上释放；
            - 类似 insert … select 这样的批量插入数据的语句，自增锁还是要等语句结束后才被释放；
          - 当 innodb_autoinc_lock_mode = 2 是性能最高的方式，但是当搭配 binlog 的日志格式是 statement 一起使用的时候，在「主从复制的场景」中会发生数据不一致的问题。
            #image("Screenshot_20250825_162104.png")
            - 但不论是哪一种，这个 binlog 拿去「从库」执行，这时从库是按「顺序」执行语句的，  只有当执行完一条 SQL 语句后，才会执行下一条 SQL。因此，在从库上「不会」发生像主库那样两个 session 「同时」执行向表 t2 中插入数据的场景。所以， 在备库上执行了 session B 的 insert 语句，生成的结果里面，id 都是连续的。这时，主从库就发生了数据不一致。
            - 要解决这问题，binlog 日志格式要设置为 row，这样在 binlog 里面记录的是主库分配的自增值，到备库执行的时候，主库的自增值是什么，从库的自增值就是什么。
            - 所以，当 innodb_autoinc_lock_mode = 2 时， 并且 binlog_format = row，既能提升并发性，又不会出现数据一致性问题。
            - 其实就是如果事务a有两条插入语句，事务b有一条插入语句，事务b的插入语句在事务a两条插入语句之间执行，在实际并发情况下，给事务a分配的id是1和3,事务b是2,但是到了binlog执行时，要先执行事务a,此时id为1,2,事务b的id为3,就出现数据不一致
            - 这时候用row日志格式只记录行数据而不是插入语句，那主库id分配情况直接用数据记录下来，就可以保证数据一致性
  - 行级锁
    - InnoDB 引擎是支持行级锁的，而 MyISAM 引擎并不支持行级锁。
    - 前面也提到，普通的 select 语句是不会对记录加锁的，因为它属于快照读。如果要在查询时对记录加行锁，可以使用下面这两个方式，  这种查询会加锁的语句称为锁定读。
      - select ... lock in share mode;
      - select ... for update;
    - 上面这两条语句必须在一个事务中，因为当事务提交了，锁就会被释放，  所以在使用这两条语句的时候，  要加上 begin、start transaction 或者 set autocommit = 0
    - 共享锁（S锁）满足读读共享，读写互斥。独占锁（X锁）满足写写互斥、读写互斥。  
    - 行级锁的类型主要有三类：
      - Record Lock，记录锁，也就是仅仅把一条记录锁上；
        - Record Lock 称为记录锁，锁住的是一条记录。而且记录锁是有 S 锁和 X 锁之分的：  
          - 当一个事务对一条记录加了 S 型记录锁后，其他事务也可以继续对该记录加 S 型记录锁（S 型与 S 锁兼容），但是不可以对该记录加 X 型记录锁（S 型与 X 锁不兼容）;
          - 当一个事务对一条记录加了 X 型记录锁后，其他事务既不可以对该记录加 S 型记录锁  （S 型与 X 锁不兼容），也不可以对该记录加 X 型记录锁（X 型与 X 锁不兼容）。
          #image("Screenshot_20250825_171329.png")
      - Gap Lock，间隙锁，锁定一个范围，但是不包含记录本身；
        - Gap Lock 称为间隙锁，存在于可重复读隔离级别和串行化隔离级别，目的是为了解决可重复读隔离级别下幻读的现象。
        -   假设，表中有一个范围 id 为（3，5）间隙锁，那么其他事务就无法插入 id = 4 这条记录了    
        #image("Screenshot_20250825_171521.png")
      - Next-Key Lock：Record Lock + Gap Lock 的组合，    锁定一个范围，并且锁定记录本身。
        -   假设，表中有一个范围 id 为（3，5\] 的 next-key lock，那么其他事务即不能插入 id = 4 记录，也不能修改 id = 5 这条记录。
        - next-key lock 是包含间隙锁+记录锁的，如果一个事务获取了 X 型的 next-key lock，那么另外一个事务在获取相同范围的 X 型的 next-key lock 时，是会被阻塞的。
        - 比如，一个事务持有了范围为 (1, 10\] 的 X 型的 next-key lock，那么另外一个事务在获取相同范围的 X 型的 next-key lock 时，就会被阻塞。
        - 虽然相同范围的间隙锁是多个事务相互兼容的，但对于记录锁，我们是要考虑 X 型与 S 型关系，X 型的记录锁与 X 型的记录锁是冲突的。
      - 插入意向锁
        - 一个事务在插入一条记录的时候，需要判断插入位置是否已被其他事务加了间隙锁（next-key lock 也包含间隙锁）。
        - 如果有的话，插入操作就会发生阻塞，直到拥有间隙锁的那个事务提交为止（释放间隙锁的时刻），在此期间会生成一个插入意向锁，表明有事务想在某个区间插入新记录，但是现在处于等待状态。
        - #image("Screenshot_20250825_172001.png")
        - 插入意向锁名字虽然有意向锁，但是它并不是意向锁，它是一种特殊的间隙锁，属于行级别锁。
        - 如果说间隙锁锁住的是一个区间，那么「插入意向锁」锁住的就是一个点。。因而从这个角度来说，插入意向锁确实是一种特殊的间隙锁。
        - 插入意向锁与间隙锁的另一个非常重要的差别是：尽管「插入意向锁」也属于间隙锁，但两个事务却不能在同一时间内，一个拥有间隙锁，另一个拥有该间隙区间内的插入意向锁  （当然，插入意向锁如果不在间隙锁区间内则是可以的）。
  - MySQL 是怎么加锁的？
    - MySQL 是怎么加行级锁的？
      - 加锁的对象是索引，加锁的基本单位是 next-key lock，它是由记录锁和间隙锁组合而成的，next-key lock 是前开后闭区间，而间隙锁是前开后开区间。
      - 但是，next-key lock 在一些场景下会退化成记录锁或间隙锁。
      - 在能使用记录锁或者间隙锁就能避免幻读现象的场景下， next-key lock 就会退化成记录锁或间隙锁。
      -  唯一索引（主键索引）等值查询
        - 当我们用唯一索引进行等值查询的时候，查询的记录存不存在，加锁的规则也会不同：
          - 当查询的记录是「存在」的，在索引树上定位到这一条记录后，将该记录的索引中的 next-key lock 会退化成「记录锁」。
          - 当查询的记录是「不存在」的，在索引树找到第一条大于该查询记录的记录后，将该记录的索引中的 next-key lock 会退化成「间隙锁」。
          #image("Screenshot_20250825_210141.png")
        - 为什么唯一索引等值查询并且查询记录存在的场景下，该记录的索引中的 next-key lock 会退化成记录锁？
          - 原因就是在唯一索引等值查询并且查询记录存在的场景下，仅靠记录锁也能避免幻读的问题。
            - 由于主键具有唯一性，所以其他事务插入 id = 1 的时候，会因为主键冲突，导致无法插入 id = 1 的新记录。
            - 由于对 id = 1 加了记录锁，其他事务无法删除该记录，这样事务 A 在多次查询 id = 1 的记录的时候，不会出现前后两次查询的结果集不同
        - 间隙锁的范围(1, 5) ，是怎么确定的？
          - 如果 LOCK_MODE 是 next-key 锁或者间隙锁，那么 LOCK_DATA 就表示锁的范围「右边界」，此次的事务 A 的 LOCK_DATA 是 5。
          - 然后锁范围的「左边界」是表中 id 为 5 的上一条记录的 id 值，即 1。
          #image("Screenshot_20250825_210719.png")
        - 为什么唯一索引等值查询并且查询记录「不存在」的场景下，在索引树找到第一条大于该查询记录的记录后，要将该记录的索引中的 next-key lock 会退化成「间隙锁」？
          - 原因就是在唯一索引等值查询并且查询记录不存在的场景下，仅靠间隙锁就能避免幻读的问题。
            - 为什么 id = 5 记录上的主键索引的锁不可以是 next-key lock？如果是 next-key lock，就意味着其他事务无法删除 id = 5 这条记录，但是这次的案例是查询 id = 2 的记录，只要保证前后两次查询 id = 2 的结果集相同，就能避免幻读的问题了，所以即使 id =5 被删除，也不会有什么影响，那就没必须加 next-key lock，因此只需要在 id = 5 加间隙锁，避免其他事务插入 id = 2 的新记录就行了。
            - 为什么不可以针对不存在的记录加记录锁？锁是加在索引上的，    而这个场景下查询的记录是不存在的，自然就没办法锁住这条不存在的记录。
      - 唯一索引（主键索引）范围查询
        - 范围查询和等值查询的加锁规则是不同的。
        - 当唯一索引进行范围查询时，会对每一个扫描到的索引加 next-key 锁，然后如果遇到下面这些情况，会退化成记录锁或者间隙锁：
          - 针对「大于等于」的范围查询，因为存在等值查询的条件，那么如果等值查询的记录是存在于表中，那么该记录的索引中的 next-key 锁会退化成记录锁。
          - 针对「小于或者小于等于」的范围查询，要看条件值的记录是否存在于表中： 
            - 当条件值的记录不在表中，那么不管是「小于」还是「小于等于」条件的范围查询，扫描到终止范围查询的记录时，该记录的索引的 next-key 锁会退化成间隙锁，其他扫描到的记录，都是在这些记录的索引上加 next-key 锁。
            - 当条件值的记录在表中，如果是「小于」条件的范围查询，扫描到终止范围查询的记录时，该记录的索引的 next-key 锁会退化成间隙锁，其他扫描到的记录，都是在这些记录的索引上加 next-key 锁；如果「小于等于」条件的范围查询，扫描到终止范围查询的记录时，该记录的索引 next-key 锁不会退化成间隙锁。其他扫描到的记录，都是在这些记录的索引上加 next-key 锁。
            #image("Screenshot_20250825_211718.png")
            #image("Screenshot_20250825_211754.png")
            #image("Screenshot_20250825_211958.png")
            #image("Screenshot_20250825_212221.png")
            #image("Screenshot_20250825_212204.png")
            #image("Screenshot_20250825_212318.png")
      - 非唯一索引等值查询
        - 当我们用非唯一索引进行等值查询的时候，因为存在两个索引，一个是主键索引，一个是非唯一索引（二级索引），所以在加锁时，同时会对这两个索引都加锁，但是对主键索引加锁的时候，只有满足查询条件的记录才会对它们的主键索引加锁。
        - 针对非唯一索引等值查询时，查询的记录存不存在，加锁的规则也会不同：
          - 当查询的记录「存在」时，由于不是唯一索引，所以肯定存在索引值相同的记录，于是非唯一索引等值查询的过程是一个扫描的过程，直到扫描到第一个不符合条件的二级索引记录就停止扫描，然后在扫描的过程中，对扫描到的二级索引记录加的是 next-key 锁，而对于第一个不符合条件的二级索引记录，该二级索引的 next-key 锁会退化成间隙锁。同时，在符合查询条件的记录的主键索引上加记录锁。
          - 当查询的记录「不存在」时，扫描到第一条不符合条件的二级索引记录，该二级索引的 next-key 锁会退化成间隙锁。因为不存在满足查询条件的记录，所以不会对主键索引加锁。
          #image("Screenshot_20250825_213215.png")
          - 当有一个事务持有二级索引的间隙锁 (22, 39) 时，什么情况下，可以让其他事务的插入 age = 22 或者 age = 39 记录的语句成功？又是什么情况下，插入 age = 22 或者 age = 39 记录时的语句会被阻塞？
          - 插入语句在插入一条记录之前，需要先定位到该记录在 B+树 的位置，如果插入的位置的下一条记录的索引上有间隙锁，才会发生阻塞。
          - 在分析二级索引的间隙锁是否可以成功插入记录时，我们要先要知道二级索引树是如何存放记录的？
            - 二级索引树是按照二级索引值（age列）按顺序存放的，在相同的二级索引值情况下， 再按主键 id 的顺序存放。知道了这个前提，我们才能知道执行插入语句的时候，插入的位置的下一条记录是谁。
            - 基于前面的实验，事务 A 是在 age = 39 记录的二级索引上，加了 X 型的间隙锁，范围是 (22, 39)。
              - 插入 age = 22 记录的成功和失败的情况分别如下：
                - 当其他事务插入一条 age = 22，id = 3 的记录的时候，在二级索引树上定位到插入的位置，而该位置的下一条是 id = 10、age = 22 的记录，该记录的二级索引上没有间隙锁，所以这条插入语句可以执行成功。
                - 当其他事务插入一条 age = 22，id = 12 的记录的时候，在二级索引树上定位到插入的位置，而该位置的下一条是 id = 20、age = 39 的记录，正好该记录的二级索引上有间隙锁，所以这条插入语句会被阻塞，无法插入成功。
              - 插入 age = 39 记录的成功和失败的情况分别如下：
                  - 当其他事务插入一条 age = 39，id = 3 的记录的时候，在二级索引树上定位到插入的位置，而该位置的下一条是 id = 20、age = 39 的记录，正好该记录的二级索引上有间隙锁，所以这条插入语句会被阻塞，无法插入成功。
                  - 当其他事务插入一条 age = 39，id = 21 的记录的时候，在二级索引树上定位到插入的位置，而该位置的下一条记录不存在，也就没有间隙锁了，所以这条插入语句可以插入成功。
              #image("Screenshot_20250825_214052.png")
              #image("Screenshot_20250825_214133.png")
              #image("Screenshot_20250825_214421.png")
              - 为什么这个实验案例中，需要在二级索引索引上加范围 (22, 39) 的间隙锁？
                #image("Screenshot_20250825_214647.png")
                #image("Screenshot_20250825_215157.png")
      -  非唯一索引范围查询
        - 非唯一索引范围查询，索引的 next-key lock 不会有退化为间隙锁和记录锁的情况
        #image("Screenshot_20250825_215508.png")
        #image("Screenshot_20250825_215444.png")
      - 没有加索引的查询
        - 如果锁定读查询语句，没有使用索引列作为查询条件，或者查询语句没有走索引查询，导致扫描是全表扫描。那么，每一条记录的索引上都会加 next-key 锁，这样就相当于锁住的全表，这时如果其他事务对该表进行增、删、改操作的时候，都会被阻塞。
        - 在线上在执行 update、delete、select ... for update等具有加锁性质的语句，一定要检查语句是否走了索引，如果是全表扫描的话，会对每一个索引加 next-key 锁，相当于把整个表锁住了，这是挺严重的问题。
  - update 没加索引会锁全表？


            






