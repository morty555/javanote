- 一致性哈希算法
  - 为什么需要一致性哈希算法
    - 若没有一致性哈希算法，有三个缓存服务器节点，NodeA,NodeB，NodeC
      - 经典哈希方案：对数据的key进行哈希计算，然后对服务器数量取模，来决定数据存放到哪台服务器上
      - 问题：扩容或缩容时，需要对几乎所有数据进行重新哈希和迁移
        - 网络带宽和IO压力大
        - 服务短暂不可用
        - 大量缓存失效，缓存雪崩，请求打到数据库
    - 一致性哈希就是解决这个问题
  - 什么是一致性哈希
    - 不再对服务器节点取模，而是将数据和节点都映射到一个固定的环形哈希空间上
    - 当一个数据需要存储时，从该数据哈希到环上的位置出发，顺时针遇到的第一个节点就是存储节点
    - 添加节点时，如A和B之间添加X，那只需要影响到AB之间的数据，因为顺时针查找只有哈希到AB之间的数才会受该X添加的影响，数据迁移量大幅降低
    - 删除节点时，假设删除节点B，那只需将B的数据迁移到他的下一个节点C
  - 基本的一致性哈希算法的问题
    - 负载不均
      - 如果节点数量少，会导致在环上每个节点分布不均，导致某些节点负责的段特别长
    - 解决方案：虚拟节点
    - 原理：对一个节点设置多个虚拟节点，每个虚拟节点都会通过哈希函数计算一个值，这个值对应环上的一个位置
    - 在使用虚拟节点后，环上节点的位置不再是成片覆盖的，不再是普通一致性哈希那样A->B->C,而是根据哈希值的不同来确定位置
    - 虚拟节点不包含数据，只是起到索引定位的作用，数据哈希到虚拟节点后要回到原节点找数据
    - 考虑场景优势
      - A节点要添加更多负载，只要给A节点分配更多的虚拟节点
      - B节点挂后数据迁移不再是只转移到下一个节点C，而是分配到所有B的虚拟节点的下一个节点，相当于分散给大多数节点，避免一个节点被打爆
      - 数据分布均匀