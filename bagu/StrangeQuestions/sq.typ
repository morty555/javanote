- 一致性哈希算法
  - 为什么需要一致性哈希算法
    - 若没有一致性哈希算法，有三个缓存服务器节点，NodeA,NodeB，NodeC
      - 经典哈希方案：对数据的key进行哈希计算，然后对服务器数量取模，来决定数据存放到哪台服务器上
      - 问题：扩容或缩容时，需要对几乎所有数据进行重新哈希和迁移
        - 网络带宽和IO压力大
        - 服务短暂不可用
        - 大量缓存失效，缓存雪崩，请求打到数据库
    - 一致性哈希就是解决这个问题
  - 什么是一致性哈希
    - 不再对服务器节点取模，而是将数据和节点都映射到一个固定的环形哈希空间上
    - 当一个数据需要存储时，从该数据哈希到环上的位置出发，顺时针遇到的第一个节点就是存储节点
    - 添加节点时，如A和B之间添加X，那只需要影响到AB之间的数据，因为顺时针查找只有哈希到AB之间的数才会受该X添加的影响，数据迁移量大幅降低
    - 删除节点时，假设删除节点B，那只需将B的数据迁移到他的下一个节点C
  - 基本的一致性哈希算法的问题
    - 负载不均
      - 如果节点数量少，会导致在环上每个节点分布不均，导致某些节点负责的段特别长
    - 解决方案：虚拟节点
    - 原理：对一个节点设置多个虚拟节点，每个虚拟节点都会通过哈希函数计算一个值，这个值对应环上的一个位置
    - 在使用虚拟节点后，环上节点的位置不再是成片覆盖的，不再是普通一致性哈希那样A->B->C,而是根据哈希值的不同来确定位置
    - 虚拟节点不包含数据，只是起到索引定位的作用，数据哈希到虚拟节点后要回到原节点找数据
    - 考虑场景优势
      - A节点要添加更多负载，只要给A节点分配更多的虚拟节点
      - B节点挂后数据迁移不再是只转移到下一个节点C，而是分配到所有B的虚拟节点的下一个节点，相当于分散给大多数节点，避免一个节点被打爆
      - 数据分布均匀

- 分布式事务模式
  - XA模式
    - 采用2pc协议
    - 系统存在TM和RM
      - TM：全局事务协调者
      - RM：本地资源管理者
    - 执行流程
      - 阶段 1：Prepare（预提交）
        - TM 向所有 RM 发送 prepare 请求。
        - RM 执行本地事务（写入 undo/redo 日志，但不提交），并返回 “可以提交/回滚”。
      - 阶段 2：Commit / Rollback
        - 若所有 RM 都返回 “可以提交”，TM 向所有 RM 发送 commit 请求。
        - 若有任何 RM 返回失败，TM 向所有 RM 发送 rollback 请求。
    - 优点
      - 强一致性，事务提交原子性完全由协调者保证。
      - 由数据库层支持
    - 缺点
      - 同步阻塞：prepare 阶段资源被锁住直到事务完成。
      - 单点风险：TM 故障可能导致资源锁死。
      - 性能差：不适合高并发场景。
    - 金融交易等强一致性要求极高的场景。
  - TCC模式
    - 将业务操作拆分为三个阶段：
      - Try 尝试执行业务，预留资源
      - Confirm 确认提交，正式生效
      - Cancel 取消操作，释放资源
    - 优点
      - 性能好，不依赖数据库层事务。
      - 灵活，可根据业务定制补偿逻辑。
      - 各分支独立，支持异步化。
    - 缺点
      - 开发成本高，业务侵入性强。
      - 每个接口都要实现 Try/Confirm/Cancel 三套逻辑。  
    - 高性能要求、可接受短暂不一致的系统。支付、账户余额、预留库存等场景
  - AT模式
    - 设计目标是：像使用本地事务一样使用分布式事务。
    - 业务只需使用本地数据库事务（\@Transactional），Seata 在底层自动接管。
    - 通过 全局锁 + Undo/Redo 日志 实现自动补偿。
    - 优点：
      - 对业务代码无侵入。
      - 易用：和本地事务几乎一样。
      - 性能比 XA 好得多。
    - 缺点：
      - 仅适用于支持 Undo/Redo 日志的关系型数据库。
      - 难以应对复杂跨系统场景（非数据库资源）。
      - 全局锁粒度较大时会有性能瓶颈。